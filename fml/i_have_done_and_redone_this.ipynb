{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ea0cf-05db-4794-ab01-3673e814d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "project/\n",
    "│\n",
    "├── app.py                # Main script to run the Streamlit app\n",
    "├── data_loader.py        # Handles loading data\n",
    "├── pages/\n",
    "│   ├── about.py          # About the project page\n",
    "│   ├── summary.py        # Data summary page\n",
    "│   ├── unique_values.py  # Unique values page\n",
    "│   ├── stats.py          # Basic statistics page\n",
    "│   ├── demographics.py   # Demographics analysis page\n",
    "│   ├── duration.py       # Process duration analysis page\n",
    "│   ├── hypothesis.py     # Hypothesis testing page\n",
    "│   └── completion.py     # Completion time analysis page\n",
    "└── utils_\n",
    "    ├── display.py        # Helper functions for displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefe78b-88e2-4178-9e6e-c8f939b72634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    url = r\"C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\clean\\combined_cleaned_data1.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"File not found. Please check the file path.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261fcaa-122a-4112-9cba-f2acd1bc0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import streamlit as st\n",
    "from data_loader import load_data  # assuming load_data is in the data_loader.py file\n",
    "from pages import about, summary, unique_values, stats, demographics, hypothesis, duration, completion\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Streamlit app for A/B Test Demo.\n",
    "    \n",
    "    Sets up the page configuration, loads data, and manages navigation\n",
    "    through different pages of the app.\n",
    "    \"\"\"\n",
    "    st.set_page_config(page_title=\"A/B Test Demo for Group 7\")\n",
    "    \n",
    "    # Load the data here\n",
    "    df = load_data()\n",
    "\n",
    "    # If df is None, show an error and don't continue\n",
    "    if df is None:\n",
    "        st.error(\"Data could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\"Select a page:\", [\n",
    "        \"About the Project\", \n",
    "        \"Data Summary\", \n",
    "        \"Unique Values\", \n",
    "        \"Basic Statistics\", \n",
    "        \"Demographics Analysis\", \n",
    "        \"Hypothesis Testing\",\n",
    "        \"Process Duration Analysis\",  # Make sure the Process Duration Analysis is listed here\n",
    "        \"Completion Time Analysis\"\n",
    "    ])\n",
    "\n",
    "    # Handle page navigation and pass the df to the page\n",
    "    if page == \"About the Project\":\n",
    "        about.show_about_project()\n",
    "    elif page == \"Data Summary\":\n",
    "        summary.show_data_summary(df)\n",
    "    elif page == \"Unique Values\":\n",
    "        unique_values.show_unique_values_in_categorical_columns(df)\n",
    "    elif page == \"Basic Statistics\":\n",
    "        stats.show_basic_statistics(df)\n",
    "    elif page == \"Demographics Analysis\":\n",
    "        demographics.show_demographics(df)  # This matches the function name in demographics.py\n",
    "    elif page == \"Process Duration Analysis\":\n",
    "        duration.show_process_duration(df)  # Ensure this matches the function name in duration.py\n",
    "    elif page == \"Hypothesis Testing\":\n",
    "        hypothesis.show_hypothesis_testing_page(df)  # Ensure this matches the function name in hypothesis.py\n",
    "    elif page == \"Completion Time Analysis\":\n",
    "        completion.show_completion_time(df)  # Make sure the function matches the one in completion.py\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac587d9-0515-4f5e-9652-97bc5366eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/about.py\n",
    "import streamlit as st\n",
    "\n",
    "def show_about_project():\n",
    "    st.title(\"About the Project\")\n",
    "    \n",
    "    st.header(\"Project Overview\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        An A/B test was set into motion from 3/15/2017 to 6/20/2017 by the Vanguard team.\n",
    "\n",
    "        Control Group: Clients interacted with Vanguard’s traditional online process.\n",
    "        Test Group: Clients experienced the new, spruced-up digital interface.\n",
    "\n",
    "        * **Day 1 & 2 (Week 5)**  \n",
    "          EDA & Data Cleaning  \n",
    "          Client behavior analysis - explained below (trying to find relations and come up with hypotheses)\n",
    "\n",
    "        * **Day 3 (Week 5)**  \n",
    "          Performance Metrics  \n",
    "          Success Indicators  \n",
    "          Redesign Outcome\n",
    "\n",
    "        * **Day 4 & 5 (Week 5)**  \n",
    "          Hypothesis Testing  \n",
    "          Completion Rate  \n",
    "          Completion Rate with a Cost-Effectiveness Threshold  \n",
    "          Other Hypothesis Examples  \n",
    "          Experiment Evaluation  \n",
    "          Design Effectiveness  \n",
    "          Duration Assessment  \n",
    "          Additional Data Needs\n",
    "\n",
    "        * **Day 1 & 2 (Week 6)**  \n",
    "          Tableau  \n",
    "          Tableau Tasks\n",
    "\n",
    "        * **Day 3 & 4 (Week 6)**\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    st.header(\"Getting Started\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        ## Metadata\n",
    "        This comprehensive set of fields will guide your analysis, helping you unravel the intricacies of client behavior and preferences.\n",
    "\n",
    "        - **client_id**: Every client’s unique ID.\n",
    "        - **variation**: Indicates if a client was part of the experiment.\n",
    "        - **visitor_id**: A unique ID for each client-device combination.\n",
    "        - **visit_id**: A unique ID for each web visit/session.\n",
    "        - **process_step**: Marks each step in the digital process.\n",
    "        - **date_time**: Timestamp of each web activity.\n",
    "        - **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "        - **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "        - **clnt_age**: Indicates the age of the client.\n",
    "        - **gendr**: Specifies the client’s gender.\n",
    "        - **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "        - **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "        - **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "        - **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months.\n",
    "\n",
    "        ## Bonus: Additional Tasks (Optional)\n",
    "        If you complete all of the tasks and have some extra time before the presentation, you can explore the following additional questions and tasks:\n",
    "\n",
    "        - Client Behavior Analysis\n",
    "        - Power and Effect Size\n",
    "        - Streamlit  \n",
    "          Add Streamlit to your project to achieve Customization and Real-time Analysis\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3681c68-b2ee-4da8-9724-34bb380d5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/summary.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "def show_data_summary(df):\n",
    "    st.subheader(\"CSV Data Overview\")\n",
    "    st.write(f\"Number of rows: {df.shape[0]}\")\n",
    "    st.write(f\"Number of columns: {df.shape[1]}\")\n",
    "    st.write(\"First 5 rows of the dataset:\")\n",
    "    st.dataframe(df.head())\n",
    "\n",
    "# Assuming you're loading your data in the main part of the app or another script\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: loading a CSV file\n",
    "    # Change the path below to your actual file location\n",
    "    df = pd.read_csv(\"path_to_your_data.csv\")  # Load data from CSV\n",
    "\n",
    "    # Now call the function and pass the DataFrame `df`\n",
    "    show_data_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54682bf2-005a-4981-b477-8c8e2c1b2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/unique_values.py\n",
    "import streamlit as st\n",
    "\n",
    "def show_unique_values_in_categorical_columns(df):\n",
    "    st.title(\"Unique Values in Categorical Columns\")\n",
    "    \n",
    "    # Get all categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Check if there are any categorical columns\n",
    "    if not categorical_columns:\n",
    "        st.warning(\"No categorical columns found in the file.\")\n",
    "        return\n",
    "\n",
    "    st.subheader(\"Unique Values in Categorical Columns:\")\n",
    "    for column in categorical_columns:\n",
    "        # Get unique values for each categorical column\n",
    "        unique_values = df[column].unique()\n",
    "        st.write(f\"Column: {column}\")\n",
    "        st.write(f\"Unique values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8d855-837d-4d90-86bb-b20fca75d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/stats.py\n",
    "import streamlit as st\n",
    "\n",
    "def show_basic_statistics(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Check if there are numeric columns\n",
    "    if numeric_df.empty:\n",
    "        st.warning(\"No numeric columns found in the file.\")\n",
    "        return\n",
    "    \n",
    "    # Display basic statistics for numeric columns\n",
    "    st.subheader(\"Basic Statistics for Numeric Columns:\")\n",
    "    statistics = numeric_df.describe().T  # Transpose for better readability\n",
    "    st.write(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05f09f-8944-4883-b02c-186be28ada98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/demographics.py\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "\n",
    "# Function to perform demographic analysis\n",
    "def analyze_demographics(df):\n",
    "    \"\"\"\n",
    "    Function to perform demographic analysis and generate interactive plots using Plotly.\n",
    "    \"\"\"\n",
    "    # Ensure 'clnt_age' is present and numeric\n",
    "    if 'clnt_age' not in df.columns:\n",
    "        st.error(\"The DataFrame does not contain the 'clnt_age' column.\")\n",
    "        return\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(df['clnt_age']):\n",
    "        st.error(\"The 'clnt_age' column is not numeric.\")\n",
    "        return\n",
    "\n",
    "    # Create the 'age_group' column based on 'clnt_age' ranges\n",
    "    bins = [0, 18, 30, 40, 50, 60, 100]  # Define the age group ranges\n",
    "    labels = ['0-18', '19-30', '31-40', '41-50', '51-60', '60+']  # Age group labels\n",
    "    df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # Debugging: Show first few rows of the dataframe to confirm 'age_group' column\n",
    "    st.write(\"First few rows of the dataframe with 'age_group':\")\n",
    "    st.write(df[['clnt_age', 'age_group']].head())\n",
    "\n",
    "    # Check if 'age_group' column exists now\n",
    "    if 'age_group' not in df.columns:\n",
    "        st.error(\"The 'age_group' column was not created.\")\n",
    "        return\n",
    "\n",
    "    # Aggregating based on 'gender' and 'age_group'\n",
    "    logs_calls_accounts = df.groupby(['gender', 'age_group']).agg({\n",
    "        'num_accts': 'mean',\n",
    "        'calls_6_mnth': 'mean',\n",
    "        'logons_6_mnth': 'mean'\n",
    "    }).reset_index().round(2)\n",
    "\n",
    "    # Debugging: Show the aggregated result\n",
    "    st.write(\"Aggregated data (grouped by 'gender' and 'age_group'):\")\n",
    "    st.write(logs_calls_accounts)\n",
    "\n",
    "    # Plot for Average Number of Accounts\n",
    "    fig1 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='num_accts', \n",
    "        color='gender',\n",
    "        title=\"Average Number of Accounts by Age Group and Gender\",\n",
    "        labels={'num_accts': 'Average Number of Accounts'},\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig1)\n",
    "\n",
    "    # Plot for Calls in the Last 6 Months\n",
    "    fig2 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='calls_6_mnth', \n",
    "        color='gender',\n",
    "        title=\"Average Calls in Last 6 Months by Age Group and Gender\",\n",
    "        labels={'calls_6_mnth': 'Average Calls in Last 6 Months'},\n",
    "        line_shape='linear',\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig2)\n",
    "\n",
    "    # Plot for Logons in the Last 6 Months\n",
    "    fig3 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='logons_6_mnth', \n",
    "        color='gender',\n",
    "        title=\"Average Logons in Last 6 Months by Age Group and Gender\",\n",
    "        labels={'logons_6_mnth': 'Average Logons in Last 6 Months'},\n",
    "        line_shape='linear',\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig3)\n",
    "\n",
    "# Function to display the demographics analysis in Streamlit\n",
    "def show_demographics(df):\n",
    "    \"\"\"\n",
    "    Show Demographics Analysis in the Streamlit app.\n",
    "    This function is used to call the analysis and display the results.\n",
    "    \"\"\"\n",
    "    st.title(\"Demographics Analysis\")\n",
    "\n",
    "    # Perform the demographic analysis (aggregation and plotting)\n",
    "    analyze_demographics(df)\n",
    "\n",
    "    # Add some explanation or results display here\n",
    "    st.write(\"Demographics analysis will be displayed here, including charts and tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea870251-9993-4d5f-97f8-25d6052fc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/duration.py\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "# Define the custom sorting order for the process steps\n",
    "process_step_order = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "# Convert 'process_step' to a categorical column with a custom sorting order\n",
    "df_merged['process_step'] = pd.Categorical(df_merged['process_step'], categories=process_step_order, ordered=True)\n",
    "\n",
    "# Filter groups based on test/control\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort the control group and test group by client_id, visit_id, process_step, and date_time\n",
    "control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "# Function to get the latest starts\n",
    "def filter_latest_starts(group_df):\n",
    "    # Filter the 'start' process step\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    \n",
    "    # Get the latest 'start' for each 'visit_id' (group by visit_id, and get the row with max date_time)\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('visit_id')['date_time'].idxmax()]\n",
    "    \n",
    "    # Merge the latest starts back with the original dataframe to keep full process after the latest start\n",
    "    return group_df.merge(latest_starts[['visit_id', 'date_time']], on=['visit_id', 'date_time'], how='inner')\n",
    "\n",
    "# Apply to both groups (Control and Test)\n",
    "filtered_control = filter_latest_starts(control_group_sorted)\n",
    "filtered_test = filter_latest_starts(test_group_sorted)\n",
    "\n",
    "# Display the complete tables for the filtered groups\n",
    "st.title(\"Control Group Sorted and Filtered\")\n",
    "st.dataframe(filtered_control)\n",
    "\n",
    "st.title(\"Test Group Sorted and Filtered\")\n",
    "st.dataframe(filtered_test)\n",
    "\n",
    "# Check if it works for a specific client (e.g., client_id == 2304905)\n",
    "client_total_entries = df_merged[df_merged[\"client_id\"] == 2304905]\n",
    "client_last_start_control = filtered_control[filtered_control['client_id'] == 2304905]\n",
    "client_last_start_test = filtered_test[filtered_test['client_id'] == 2304905]\n",
    "\n",
    "# Display the results for the specific client\n",
    "st.title(\"Total Entries for Client 2304905\")\n",
    "st.dataframe(client_total_entries)\n",
    "\n",
    "st.title(\"Last Start for Client 2304905 in Control Group\")\n",
    "st.dataframe(client_last_start_control)\n",
    "\n",
    "st.title(\"Last Start for Client 2304905 in Test Group\")\n",
    "st.dataframe(client_last_start_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba62f24e-2582-4382-9a4f-d7b41d32868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/hypothesis.py\n",
    "import streamlit as st\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Function for two-proportion z-test\n",
    "def two_proportion_z_test(p1, p2, n1, n2):\n",
    "    P = (p1 * n1 + p2 * n2) / (n1 + n2)\n",
    "    SE = (P * (1 - P) * (1 / n1 + 1 / n2)) ** 0.5\n",
    "    z = (p1 - p2) / SE\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))  # Two-tailed test\n",
    "    return z, p_value\n",
    "\n",
    "# Function to show hypothesis testing page\n",
    "def show_hypothesis_testing_page(df):\n",
    "    st.title(\"Hypothesis Testing for Completion Rates\")\n",
    "    \n",
    "    # Check if 'completion_rate' exists, otherwise create it\n",
    "    if 'completion_rate' not in df.columns:\n",
    "        if 'completed_visits' in df.columns and 'started_visits' in df.columns:\n",
    "            df['completion_rate'] = df['completed_visits'] / df['started_visits'] * 100\n",
    "        else:\n",
    "            st.error(\"Missing required columns ('completed_visits' or 'started_visits') to calculate 'completion_rate'.\")\n",
    "            return  # Exit function if required columns are missing\n",
    "    \n",
    "    # Separate control and test groups based on 'variation' column\n",
    "    if 'variation' not in df.columns:\n",
    "        st.error(\"Missing 'variation' column to distinguish between control and test groups.\")\n",
    "        return\n",
    "\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "    \n",
    "    if control_group.empty or test_group.empty:\n",
    "        st.error(\"Missing data for control or test group.\")\n",
    "        return\n",
    "\n",
    "    steps = ['confirm', 'step_1', 'step_2', 'step_3']\n",
    "\n",
    "    # Iterate through the steps to perform hypothesis testing for completion rates\n",
    "    for step in steps:\n",
    "        st.subheader(f\"Step: {step}\")\n",
    "        \n",
    "        control_completions = control_group[control_group['process_step'] == step]['completion_rate'].mean()\n",
    "        test_completions = test_group[test_group['process_step'] == step]['completion_rate'].mean()\n",
    "        \n",
    "        control_total = control_group[control_group['process_step'] == step]['started_visits'].sum()\n",
    "        test_total = test_group[test_group['process_step'] == step]['started_visits'].sum()\n",
    "\n",
    "        if control_total == 0 or test_total == 0:\n",
    "            st.warning(f\"No visits started for control or test group at step {step}. Skipping hypothesis test for this step.\")\n",
    "            continue\n",
    "        \n",
    "        p_control = control_completions / 100\n",
    "        p_test = test_completions / 100\n",
    "        \n",
    "        z_stat, p_value = two_proportion_z_test(p_control, p_test, control_total, test_total)\n",
    "        \n",
    "        st.write(f\"Z-statistic: {z_stat:.4f}\")\n",
    "        st.write(f\"P-value: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            st.write(f\"**Reject the null hypothesis**: There is a significant difference in completion rates between control and test group for step: {step}.\")\n",
    "        else:\n",
    "            st.write(f\"**Fail to reject the null hypothesis**: There is no significant difference in completion rates between control and test group for step: {step}.\")\n",
    "        st.write(\"\\n\")\n",
    "\n",
    "    st.subheader(\"Hypothesis Test: Tenure\")\n",
    "    \n",
    "    # Drop duplicates based on 'client_id' to ensure we are comparing unique clients\n",
    "    control_unique = control_group.drop_duplicates(subset='client_id')\n",
    "    test_unique = test_group.drop_duplicates(subset='client_id')\n",
    "\n",
    "    # Ensure 'clnt_tenure_yr' exists in the dataset\n",
    "    if 'clnt_tenure_yr' not in df.columns:\n",
    "        st.error(\"Missing 'clnt_tenure_yr' column for tenure analysis.\")\n",
    "        return\n",
    "    \n",
    "    control_tenure = control_unique['clnt_tenure_yr']\n",
    "    test_tenure = test_unique['clnt_tenure_yr']\n",
    "        \n",
    "    t_stat, p_value_tenure = stats.ttest_ind(control_tenure, test_tenure, equal_var=True)\n",
    "\n",
    "    st.write(f\"Average Tenure in Control group: {control_tenure.mean():.2f} years\")\n",
    "    st.write(f\"Average Tenure in Test group: {test_tenure.mean():.2f} years\")\n",
    "    st.write(f\"T-statistic: {t_stat:.4f}\")\n",
    "    st.write(f\"P-value: {p_value_tenure:.4f}\")\n",
    "\n",
    "    if p_value_tenure < 0.05:\n",
    "        st.write(\"**Reject the null hypothesis**: There is a significant difference in tenure between control and test groups.\")\n",
    "    else:\n",
    "        st.write(\"**Fail to reject the null hypothesis**: There is no significant difference in tenure between control and test groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b278fdc-cdb0-4420-95ac-5ac6ed7a29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/completion.py\n",
    "import streamlit as st\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "def show_completion_time(df):\n",
    "    st.title(\"Completion Time Analysis\")\n",
    "    \n",
    "    # Ensure the 'date_time' column is in datetime format\n",
    "    if 'date_time' not in df.columns:\n",
    "        st.error(\"Missing 'date_time' column in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Coerce errors to NaT (Not a Time)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')  \n",
    "\n",
    "    # Drop rows where 'date_time' is NaT after coercion\n",
    "    df = df.dropna(subset=['date_time'])\n",
    "\n",
    "    # Calculate the completion time for each process step\n",
    "    df['next_step_time'] = df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Ensure 'next_step_time' is not NaT before computing completion time\n",
    "    df = df.dropna(subset=['next_step_time'])\n",
    "\n",
    "    df['completion_time'] = df['next_step_time'] - df['date_time']\n",
    "    \n",
    "    # Display average completion time per process step\n",
    "    st.subheader(\"Average Completion Time Per Process Step\")\n",
    "    st.write(df.groupby('process_step')['completion_time'].mean())\n",
    "\n",
    "    # Now, calculate completion rate for within-visit and client-based analysis\n",
    "    st.subheader(\"Completion Rate by Visit\")\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "    \n",
    "    # Completion rate based on visit_id\n",
    "    def calculate_within_visit_completion_rate(group):\n",
    "        # Total unique visits that started\n",
    "        started_visits = group[group['process_step'] == 'start']['visit_id'].nunique()\n",
    "\n",
    "        # Unique visits that completed each step\n",
    "        completed_visits = (\n",
    "            group[group['process_step'] != 'start']\n",
    "            .groupby('process_step')['visit_id']\n",
    "            .nunique()\n",
    "            .reset_index(name='completed_visits')\n",
    "        )\n",
    "\n",
    "        # Add the total started visits as a constant column\n",
    "        completed_visits['started_visits'] = started_visits\n",
    "\n",
    "        # Calculate the completion rate\n",
    "        completed_visits['completion_rate'] = (\n",
    "            completed_visits['completed_visits'] / completed_visits['started_visits']\n",
    "        ) * 100\n",
    "\n",
    "        return completed_visits\n",
    "\n",
    "    # Calculate completion rates for the control and test groups\n",
    "    control_completion_rate = calculate_within_visit_completion_rate(control_group)\n",
    "    test_completion_rate = calculate_within_visit_completion_rate(test_group)\n",
    "\n",
    "    # Display completion rates for control and test groups\n",
    "    st.write(\"Control Group Completion Rate by Visit:\")\n",
    "    st.dataframe(control_completion_rate)\n",
    "\n",
    "    st.write(\"Test Group Completion Rate by Visit:\")\n",
    "    st.dataframe(test_completion_rate)\n",
    "\n",
    "    # Completion rate based on client_id\n",
    "    def calculate_within_visit_completion_rate_by_client(group):\n",
    "        # Total unique visits that started\n",
    "        started_visits = group[group['process_step'] == 'start']['client_id'].nunique()\n",
    "\n",
    "        # Unique visits that completed each step\n",
    "        completed_visits = (\n",
    "            group[group['process_step'] != 'start']\n",
    "            .groupby('process_step')['client_id']\n",
    "            .nunique()\n",
    "            .reset_index(name='completed_visits')\n",
    "        )\n",
    "\n",
    "        # Add the total started visits as a constant column\n",
    "        completed_visits['started_visits'] = started_visits\n",
    "\n",
    "        # Calculate the completion rate\n",
    "        completed_visits['completion_rate'] = (\n",
    "            completed_visits['completed_visits'] / completed_visits['started_visits']\n",
    "        ) * 100\n",
    "\n",
    "        return completed_visits\n",
    "\n",
    "    # Calculate completion rates for the control and test groups based on client_id\n",
    "    control_completion_rate_id = calculate_within_visit_completion_rate_by_client(control_group)\n",
    "    test_completion_rate_id = calculate_within_visit_completion_rate_by_client(test_group)\n",
    "\n",
    "    # Display completion rates for control and test groups based on client_id\n",
    "    st.write(\"Control Group Completion Rate by Client:\")\n",
    "    st.dataframe(control_completion_rate_id)\n",
    "\n",
    "    st.write(\"Test Group Completion Rate by Client:\")\n",
    "    st.dataframe(test_completion_rate_id)\n",
    "\n",
    "    # Completion rate by age group\n",
    "    def calculate_within_visit_completion_rate_by_age(group):\n",
    "        # Total unique visits that started\n",
    "        started_visits = group[group['process_step'] == 'start']['client_id'].nunique()\n",
    "\n",
    "        # Unique visits that completed each step, grouped by age_group\n",
    "        completed_visits = (\n",
    "            group[group['process_step'] != 'start']\n",
    "            .groupby(['process_step', 'age_group'])['client_id']\n",
    "            .nunique()\n",
    "            .reset_index(name='completed_visits')\n",
    "        )\n",
    "\n",
    "        # Add the total started visits as a constant column\n",
    "        completed_visits['started_visits'] = started_visits\n",
    "\n",
    "        # Calculate the completion rate\n",
    "        completed_visits['completion_rate'] = (\n",
    "            completed_visits['completed_visits'] / completed_visits['started_visits']\n",
    "        ) * 100\n",
    "\n",
    "        return completed_visits\n",
    "\n",
    "    # Calculate completion rates for the control and test groups based on age group\n",
    "    control_completion_rate_by_age = calculate_within_visit_completion_rate_by_age(control_group)\n",
    "    test_completion_rate_by_age = calculate_within_visit_completion_rate_by_age(test_group)\n",
    "\n",
    "    # Display completion rates by age group\n",
    "    st.write(\"Control Group Completion Rate by Age:\")\n",
    "    st.dataframe(control_completion_rate_by_age)\n",
    "\n",
    "    st.write(\"Test Group Completion Rate by Age:\")\n",
    "    st.dataframe(test_completion_rate_by_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b8b39-13de-4087-b6a3-cc2fe1e80560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447293be-8da0-4b34-9642-58ebc229a39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519591a6-0cc8-4ffd-976f-ba80bf5761ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee1a38-eb71-4ab2-a21c-9ad96f657e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167da054-1c91-4986-9375-59534cc6378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/display.py\n",
    "import streamlit as st\n",
    "\n",
    "# Function to show an error message\n",
    "def show_error(message: str):\n",
    "    st.error(message)\n",
    "\n",
    "# Function to display a dataframe\n",
    "def display_dataframe(df, rows=5):\n",
    "    if df is not None:\n",
    "        st.dataframe(df.head(rows))\n",
    "    else:\n",
    "        show_error(\"Data is not available.\")\n",
    "\n",
    "# Function to display basic statistics of the dataframe\n",
    "def show_basic_statistics(df):\n",
    "    if df is not None:\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        if not numeric_df.empty:\n",
    "            st.subheader(\"Basic Statistics\")\n",
    "            st.write(numeric_df.describe().T)\n",
    "        else:\n",
    "            show_error(\"No numeric columns found for statistics.\")\n",
    "    else:\n",
    "        show_error(\"Data is not available for statistics.\")\n",
    "\n",
    "# Function to show unique values for categorical columns\n",
    "def show_unique_values(df):\n",
    "    if df is not None:\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if categorical_columns:\n",
    "            for column in categorical_columns:\n",
    "                st.write(f\"Column: {column}\")\n",
    "                st.write(f\"Unique values: {df[column].unique()}\")\n",
    "        else:\n",
    "            show_error(\"No categorical columns found.\")\n",
    "    else:\n",
    "        show_error(\"Data is not available for unique value display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
