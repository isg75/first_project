{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ea0cf-05db-4794-ab01-3673e814d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "project/\n",
    "│\n",
    "├── app.py                # Main script to run the Streamlit app\n",
    "├── data_loader.py        # Handles loading data\n",
    "├── pages/\n",
    "│   ├── about.py          # About the project page\n",
    "│   ├── summary.py        # Data summary page\n",
    "│   ├── unique_values.py  # Unique values page\n",
    "│   ├── stats.py          # Basic statistics page\n",
    "│   ├── demographics.py   # Demographics analysis page\n",
    "│   ├── duration.py       # Process duration analysis page\n",
    "│   ├── hypothesis.py     # Hypothesis testing page\n",
    "│   ├── completion.py     # Completion time analysis page\n",
    "│   ├── bounce_rate.py    # Bounce rate analysis page \n",
    "│   ├── error_rate.py\n",
    "└── utils_\n",
    "    ├── display.py        # Helper functions for displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefe78b-88e2-4178-9e6e-c8f939b72634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    url = r\"C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\clean\\combined_cleaned_data1.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"File not found. Please check the file path.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261fcaa-122a-4112-9cba-f2acd1bc0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import streamlit as st\n",
    "from data_loader import load_data  # Assuming load_data is in the data_loader.py file\n",
    "from pages import about, summary, unique_values, stats, demographics, hypothesistestcompletionrate, duration, completion, error_rate\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Streamlit app for A/B Test Demo.\n",
    "    \n",
    "    Sets up the page configuration, loads data, and manages navigation\n",
    "    through different pages of the app.\n",
    "    \"\"\"\n",
    "    st.set_page_config(page_title=\"A/B Test Demo for Group 7\")\n",
    "    \n",
    "    # Load the data here\n",
    "    df = load_data()\n",
    "\n",
    "    # If df is None, show an error and don't continue\n",
    "    if df is None:\n",
    "        st.error(\"Data could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    # Sort the data into control and test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "    # Add age categorization (as it seems to be a necessary step in some of the analysis)\n",
    "    bins = [0, 30, 40, 50, 100] \n",
    "    labels = ['Under 30', '30-39', '40-49', '50 and above']\n",
    "    df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels)\n",
    "    control_group_sorted['age_group'] = pd.cut(control_group_sorted['clnt_age'], bins=bins, labels=labels)\n",
    "    test_group_sorted['age_group'] = pd.cut(test_group_sorted['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\"Select a page:\", [\n",
    "        \"About the Project\", \n",
    "        \"Data Summary\", \n",
    "        \"Unique Values\", \n",
    "        \"Basic Statistics\", \n",
    "        \"Demographics Analysis\", \n",
    "        \"Hypothesis Testing Completion Rate\", \n",
    "        \"Process Duration Analysis\",  \n",
    "        \"Completion Time Analysis\",\n",
    "        \"Error Rate Hypothesis Testing\"  # Added Error Rate Hypothesis Testing\n",
    "    ])\n",
    "\n",
    "    # Handle page navigation and pass the df and sorted groups to the page\n",
    "    if page == \"About the Project\":\n",
    "        about.show_about_project()\n",
    "    elif page == \"Data Summary\":\n",
    "        summary.show_data_summary(df)\n",
    "    elif page == \"Unique Values\":\n",
    "        unique_values.show_unique_values_in_categorical_columns(df)\n",
    "    elif page == \"Basic Statistics\":\n",
    "        stats.show_basic_statistics(df)\n",
    "    elif page == \"Demographics Analysis\":\n",
    "        demographics.show_demographics(df, control_group_sorted, test_group_sorted)  # Pass sorted groups here\n",
    "    elif page == \"Hypothesis Testing Completion Rate\":\n",
    "        hypothesistestcompletionrate.show_page(df)\n",
    "    elif page == \"Process Duration Analysis\":\n",
    "        duration.show_process_duration(df)\n",
    "    elif page == \"Completion Time Analysis\":\n",
    "        completion.show_completion_time(df)\n",
    "    elif page == \"Error Rate Hypothesis Testing\":\n",
    "        error_rate.show_error_rate_analysis(df)  # Link to error_rate.py\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac587d9-0515-4f5e-9652-97bc5366eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/about.py\n",
    "import streamlit as st\n",
    "\n",
    "def show_about_project():\n",
    "    st.title(\"About the Project\")\n",
    "    \n",
    "    st.header(\"Project Overview\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        An A/B test was set into motion from 3/15/2017 to 6/20/2017 by the Vanguard team.\n",
    "\n",
    "        Control Group: Clients interacted with Vanguard’s traditional online process.\n",
    "        Test Group: Clients experienced the new, spruced-up digital interface.\n",
    "\n",
    "        * **Day 1 & 2 (Week 5)**  \n",
    "          EDA & Data Cleaning  \n",
    "          Client behavior analysis - explained below (trying to find relations and come up with hypotheses)\n",
    "\n",
    "        * **Day 3 (Week 5)**  \n",
    "          Performance Metrics  \n",
    "          Success Indicators  \n",
    "          Redesign Outcome\n",
    "\n",
    "        * **Day 4 & 5 (Week 5)**  \n",
    "          Hypothesis Testing  \n",
    "          Completion Rate  \n",
    "          Completion Rate with a Cost-Effectiveness Threshold  \n",
    "          Other Hypothesis Examples  \n",
    "          Experiment Evaluation  \n",
    "          Design Effectiveness  \n",
    "          Duration Assessment  \n",
    "          Additional Data Needs\n",
    "\n",
    "        * **Day 1 & 2 (Week 6)**  \n",
    "          Tableau  \n",
    "          Tableau Tasks\n",
    "\n",
    "        * **Day 3 & 4 (Week 6)**\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    st.header(\"Getting Started\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        ## Metadata\n",
    "        This comprehensive set of fields will guide your analysis, helping you unravel the intricacies of client behavior and preferences.\n",
    "\n",
    "        - **client_id**: Every client’s unique ID.\n",
    "        - **variation**: Indicates if a client was part of the experiment.\n",
    "        - **visitor_id**: A unique ID for each client-device combination.\n",
    "        - **visit_id**: A unique ID for each web visit/session.\n",
    "        - **process_step**: Marks each step in the digital process.\n",
    "        - **date_time**: Timestamp of each web activity.\n",
    "        - **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "        - **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "        - **clnt_age**: Indicates the age of the client.\n",
    "        - **gendr**: Specifies the client’s gender.\n",
    "        - **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "        - **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "        - **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "        - **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months.\n",
    "\n",
    "        ## Bonus: Additional Tasks (Optional)\n",
    "        If you complete all of the tasks and have some extra time before the presentation, you can explore the following additional questions and tasks:\n",
    "\n",
    "        - Client Behavior Analysis\n",
    "        - Power and Effect Size\n",
    "        - Streamlit  \n",
    "          Add Streamlit to your project to achieve Customization and Real-time Analysis\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3681c68-b2ee-4da8-9724-34bb380d5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/summary.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "def show_data_summary(df):\n",
    "    st.subheader(\"CSV Data Overview\")\n",
    "    st.write(f\"Number of rows: {df.shape[0]}\")\n",
    "    st.write(f\"Number of columns: {df.shape[1]}\")\n",
    "    st.write(\"First 5 rows of the dataset:\")\n",
    "    st.dataframe(df.head())\n",
    "\n",
    "# Assuming you're loading your data in the main part of the app or another script\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: loading a CSV file\n",
    "    # Change the path below to your actual file location\n",
    "    df = pd.read_csv(\"path_to_your_data.csv\")  # Load data from CSV\n",
    "\n",
    "    # Now call the function and pass the DataFrame `df`\n",
    "    show_data_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54682bf2-005a-4981-b477-8c8e2c1b2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/unique_values.py\n",
    "import streamlit as st\n",
    "\n",
    "def show_unique_values_in_categorical_columns(df):\n",
    "    st.title(\"Unique Values in Categorical Columns\")\n",
    "    \n",
    "    # Get all categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Check if there are any categorical columns\n",
    "    if not categorical_columns:\n",
    "        st.warning(\"No categorical columns found in the file.\")\n",
    "        return\n",
    "\n",
    "    st.subheader(\"Unique Values in Categorical Columns:\")\n",
    "    for column in categorical_columns:\n",
    "        # Get unique values for each categorical column\n",
    "        unique_values = df[column].unique()\n",
    "        st.write(f\"Column: {column}\")\n",
    "        st.write(f\"Unique values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8d855-837d-4d90-86bb-b20fca75d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/stats.py\n",
    "import streamlit as st\n",
    "\n",
    "def show_basic_statistics(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Check if there are numeric columns\n",
    "    if numeric_df.empty:\n",
    "        st.warning(\"No numeric columns found in the file.\")\n",
    "        return\n",
    "    \n",
    "    # Display basic statistics for numeric columns\n",
    "    st.subheader(\"Basic Statistics for Numeric Columns:\")\n",
    "    statistics = numeric_df.describe().T  # Transpose for better readability\n",
    "    st.write(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05f09f-8944-4883-b02c-186be28ada98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/demographics.py\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "\n",
    "# Function to perform demographic analysis\n",
    "def analyze_demographics(df, control_group_sorted, test_group_sorted):\n",
    "    \"\"\"\n",
    "    Function to perform demographic analysis and generate interactive plots using Plotly.\n",
    "    \"\"\"\n",
    "    # Ensure 'clnt_age' is present and numeric\n",
    "    if 'clnt_age' not in df.columns:\n",
    "        st.error(\"The DataFrame does not contain the 'clnt_age' column.\")\n",
    "        return\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(df['clnt_age']):\n",
    "        st.error(\"The 'clnt_age' column is not numeric.\")\n",
    "        return\n",
    "\n",
    "    # Create the 'age_group' column based on 'clnt_age' ranges\n",
    "    bins = [0, 18, 30, 40, 50, 60, 100]  # Define the age group ranges\n",
    "    labels = ['0-18', '19-30', '31-40', '41-50', '51-60', '60+']  # Age group labels\n",
    "    df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # Debugging: Show first few rows of the dataframe to confirm 'age_group' column\n",
    "    st.write(\"First few rows of the dataframe with 'age_group':\")\n",
    "    st.write(df[['clnt_age', 'age_group']].head())\n",
    "\n",
    "    # Check if 'age_group' column exists now\n",
    "    if 'age_group' not in df.columns:\n",
    "        st.error(\"The 'age_group' column was not created.\")\n",
    "        return\n",
    "\n",
    "    # Aggregating based on 'gender' and 'age_group'\n",
    "    logs_calls_accounts = df.groupby(['gender', 'age_group']).agg({\n",
    "        'num_accts': 'mean',\n",
    "        'calls_6_mnth': 'mean',\n",
    "        'logons_6_mnth': 'mean'\n",
    "    }).reset_index().round(2)\n",
    "\n",
    "    # Debugging: Show the aggregated result\n",
    "    st.write(\"Aggregated data (grouped by 'gender' and 'age_group'):\")\n",
    "    st.write(logs_calls_accounts)\n",
    "\n",
    "    # Plot for Average Number of Accounts\n",
    "    fig1 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='num_accts', \n",
    "        color='gender',\n",
    "        title=\"Average Number of Accounts by Age Group and Gender\",\n",
    "        labels={'num_accts': 'Average Number of Accounts'},\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig1)\n",
    "\n",
    "    # Plot for Calls in the Last 6 Months\n",
    "    fig2 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='calls_6_mnth', \n",
    "        color='gender',\n",
    "        title=\"Average Calls in Last 6 Months by Age Group and Gender\",\n",
    "        labels={'calls_6_mnth': 'Average Calls in Last 6 Months'},\n",
    "        line_shape='linear',\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig2)\n",
    "\n",
    "    # Plot for Logons in the Last 6 Months\n",
    "    fig3 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='logons_6_mnth', \n",
    "        color='gender',\n",
    "        title=\"Average Logons in Last 6 Months by Age Group and Gender\",\n",
    "        labels={'logons_6_mnth': 'Average Logons in Last 6 Months'},\n",
    "        line_shape='linear',\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig3)\n",
    "\n",
    "    # *** Age Group by Test & Control ***\n",
    "    st.write(\"### Test & Control Grouped by Age Group\")\n",
    "    # Filter based on unique client_id in control and test groups\n",
    "    control_unique = control_group_sorted.drop_duplicates(subset='client_id')\n",
    "    test_unique = test_group_sorted.drop_duplicates(subset='client_id')\n",
    "\n",
    "    # Calculate age group distribution for each group\n",
    "    control_age_group = control_unique[\"age_group\"].value_counts()\n",
    "    test_age_group = test_unique[\"age_group\"].value_counts()\n",
    "\n",
    "    # Combine data into one table\n",
    "    age_groups_concat = pd.concat(\n",
    "        [control_age_group, test_age_group], \n",
    "        axis=1, \n",
    "        keys=[\"Control Group Count\", \"Test Group Count\"]\n",
    "    )\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    age_groups_concat = age_groups_concat.sort_values(by=\"age_group\", ascending=True)  # sort values\n",
    "    age_groups_concat = age_groups_concat.reset_index()\n",
    "\n",
    "    st.write(age_groups_concat)\n",
    "\n",
    "    # *** Age Group x Gender ***\n",
    "    st.write(\"### Age Group x Gender\")\n",
    "    control_age_group_gender = control_unique.groupby(\"age_group\")[\"gender\"].value_counts().unstack()\n",
    "    test_age_group_gender = test_unique.groupby(\"age_group\")[\"gender\"].value_counts().unstack()\n",
    "\n",
    "    # Reset the index to create a proper DataFrame structure\n",
    "    control_age_group_gender = control_age_group_gender.reset_index()\n",
    "    test_age_group_gender = test_age_group_gender.reset_index()\n",
    "\n",
    "    st.write(\"Control Group - Age Group x Gender:\")\n",
    "    st.write(control_age_group_gender)\n",
    "\n",
    "    st.write(\"Test Group - Age Group x Gender:\")\n",
    "    st.write(test_age_group_gender)\n",
    "\n",
    "    # *** Age Group x Balances ***\n",
    "    st.write(\"### Age Group x Balances\")\n",
    "    # Filter control and test group based on unique client_id\n",
    "    control_age_group_balance = control_unique.groupby(\"age_group\")[\"balance\"].mean().round(2)\n",
    "    test_age_group_balance = test_unique.groupby(\"age_group\")[\"balance\"].mean().round(2)\n",
    "\n",
    "    # Convert the grouped Series to DataFrames\n",
    "    control_age_group_balance_df = control_age_group_balance.reset_index()\n",
    "    test_age_group_balance_df = test_age_group_balance.reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    control_age_group_balance_df.rename(columns={\"age_group\": \"Age Group\", \"balance\": \"Control Group Balance\"}, inplace=True)\n",
    "    test_age_group_balance_df.rename(columns={\"age_group\": \"Age Group\", \"balance\": \"Test Group Balance\"}, inplace=True)\n",
    "\n",
    "    # Merge both control and test balance data into a single table\n",
    "    balance_concat = pd.merge(control_age_group_balance_df, test_age_group_balance_df, on=\"Age Group\")\n",
    "\n",
    "    st.write(balance_concat)\n",
    "\n",
    "# Function to display the demographics analysis in Streamlit\n",
    "def show_demographics(df, control_group_sorted, test_group_sorted):\n",
    "    \"\"\"\n",
    "    Show Demographics Analysis in the Streamlit app.\n",
    "    This function is used to call the analysis and display the results.\n",
    "    \"\"\"\n",
    "    st.title(\"Demographics Analysis\")\n",
    "\n",
    "    # Perform the demographic analysis (aggregation and plotting)\n",
    "    analyze_demographics(df, control_group_sorted, test_group_sorted)\n",
    "\n",
    "    # Additional notes or user guidance\n",
    "    st.write(\"\"\"\n",
    "        This page provides demographic analysis, including average number of accounts, calls, \n",
    "        and logons, based on age groups and gender. The plots above allow you to explore how \n",
    "        these variables differ across age groups and between genders.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea870251-9993-4d5f-97f8-25d6052fc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/duration.py\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "# Define the custom sorting order for the process steps\n",
    "process_step_order = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "\n",
    "# Convert 'process_step' to a categorical column with a custom sorting order\n",
    "df_merged['process_step'] = pd.Categorical(df_merged['process_step'], categories=process_step_order, ordered=True)\n",
    "\n",
    "# Filter groups based on test/control\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort the control group and test group by client_id, visit_id, process_step, and date_time\n",
    "control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "# Function to get the latest starts\n",
    "def filter_latest_starts(group_df):\n",
    "    # Filter the 'start' process step\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    \n",
    "    # Get the latest 'start' for each 'visit_id' (group by visit_id, and get the row with max date_time)\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('visit_id')['date_time'].idxmax()]\n",
    "    \n",
    "    # Merge the latest starts back with the original dataframe to keep full process after the latest start\n",
    "    return group_df.merge(latest_starts[['visit_id', 'date_time']], on=['visit_id', 'date_time'], how='inner')\n",
    "\n",
    "# Apply to both groups (Control and Test)\n",
    "filtered_control = filter_latest_starts(control_group_sorted)\n",
    "filtered_test = filter_latest_starts(test_group_sorted)\n",
    "\n",
    "# Display the complete tables for the filtered groups\n",
    "st.title(\"Control Group Sorted and Filtered\")\n",
    "st.dataframe(filtered_control)\n",
    "\n",
    "st.title(\"Test Group Sorted and Filtered\")\n",
    "st.dataframe(filtered_test)\n",
    "\n",
    "# Check if it works for a specific client (e.g., client_id == 2304905)\n",
    "client_total_entries = df_merged[df_merged[\"client_id\"] == 2304905]\n",
    "client_last_start_control = filtered_control[filtered_control['client_id'] == 2304905]\n",
    "client_last_start_test = filtered_test[filtered_test['client_id'] == 2304905]\n",
    "\n",
    "# Display the results for the specific client\n",
    "st.title(\"Total Entries for Client 2304905\")\n",
    "st.dataframe(client_total_entries)\n",
    "\n",
    "st.title(\"Last Start for Client 2304905 in Control Group\")\n",
    "st.dataframe(client_last_start_control)\n",
    "\n",
    "st.title(\"Last Start for Client 2304905 in Test Group\")\n",
    "st.dataframe(client_last_start_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba62f24e-2582-4382-9a4f-d7b41d32868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/hypothesistestcompletionrate.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def show_page(df):\n",
    "    \"\"\"\n",
    "    Function to display hypothesis testing results for completion rates\n",
    "    between Control and Test groups.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the necessary columns exist\n",
    "    if 'completion' not in df.columns:\n",
    "        st.error(\"The 'completion' column is missing from the dataset.\")\n",
    "        return\n",
    "    if 'variation' not in df.columns:\n",
    "        st.error(\"The 'variation' column is missing from the dataset.\")\n",
    "        return\n",
    "\n",
    "    # Filter the control and test groups from the dataframe\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    # Calculate completion rates for both groups\n",
    "    control_rate = control_group['completion'].mean()  # Assuming 'completion' column indicates completion\n",
    "    test_rate = test_group['completion'].mean()\n",
    "\n",
    "    # Display the completion rates\n",
    "    st.subheader(\"Completion Rates\")\n",
    "    st.write(f\"Control Group Completion Rate: {control_rate:.2%}\")\n",
    "    st.write(f\"Test Group Completion Rate: {test_rate:.2%}\")\n",
    "\n",
    "    # Perform a hypothesis test to compare completion rates (e.g., z-test for proportions)\n",
    "    # Null hypothesis: The completion rates are equal\n",
    "    # Alternative hypothesis: The completion rates are different\n",
    "\n",
    "    # Sample size for both groups\n",
    "    n_control = len(control_group)\n",
    "    n_test = len(test_group)\n",
    "\n",
    "    # Perform z-test for proportions (for large samples, z-test is used to compare two proportions)\n",
    "    control_successes = control_group['completion'].sum()\n",
    "    test_successes = test_group['completion'].sum()\n",
    "\n",
    "    # Perform z-test (z-test for two proportions)\n",
    "    success_counts = [control_successes, test_successes]\n",
    "    sample_sizes = [n_control, n_test]\n",
    "    \n",
    "    # Perform z-test for proportions\n",
    "    z_stat, p_value = stats.proportions_ztest(success_counts, sample_sizes)\n",
    "\n",
    "    # Display p-value and decision\n",
    "    st.subheader(\"Hypothesis Test Results\")\n",
    "    st.write(f\"P-value for comparison of completion rates: {p_value:.4f}\")\n",
    "\n",
    "    # Hypothesis test interpretation\n",
    "    if p_value < 0.05:\n",
    "        st.write(\"The difference in completion rates is statistically significant.\")\n",
    "    else:\n",
    "        st.write(\"The difference in completion rates is not statistically significant.\")\n",
    "\n",
    "    # Optional: Plot completion rates for visual comparison\n",
    "    st.subheader(\"Completion Rates Comparison\")\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Group': ['Control', 'Test'],\n",
    "        'Completion Rate': [control_rate, test_rate]\n",
    "    })\n",
    "    \n",
    "    st.bar_chart(comparison_df.set_index('Group')['Completion Rate'])\n",
    "\n",
    "    # Optional: Display a brief explanation of the hypothesis test\n",
    "    st.subheader(\"Hypothesis Testing Explanation\")\n",
    "    st.write(\"\"\"\n",
    "    In this test, we are comparing the completion rates between the Control and Test groups.\n",
    "    \n",
    "    - **Null Hypothesis (H₀):** The completion rates for both groups are the same.\n",
    "    - **Alternative Hypothesis (H₁):** The completion rates for both groups are different.\n",
    "    \n",
    "    A p-value less than 0.05 indicates that the null hypothesis can be rejected, meaning the difference in completion rates is statistically significant.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b278fdc-cdb0-4420-95ac-5ac6ed7a29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/completion.py\n",
    "import streamlit as st\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "def show_completion_time(df):\n",
    "    st.title(\"Completion Time Analysis\")\n",
    "    \n",
    "    # Ensure the 'date_time' column is in datetime format\n",
    "    if 'date_time' not in df.columns:\n",
    "        st.error(\"Missing 'date_time' column in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Coerce errors to NaT (Not a Time)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')  \n",
    "\n",
    "    # Drop rows where 'date_time' is NaT after coercion\n",
    "    df = df.dropna(subset=['date_time'])\n",
    "\n",
    "    # Sort the dataset to ensure chronological order by client_id, visit_id, and date_time\n",
    "    df = df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "    \n",
    "    # Split the data into control and test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "    \n",
    "    # Function to calculate completion time for each step considering multiple visits\n",
    "    def calculate_completion_time_with_visits(group_df):\n",
    "        group_df = group_df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "        group_df['next_step_time'] = group_df.groupby(['client_id', 'visit_id'])['date_time'].shift(-1)\n",
    "        group_df = group_df.dropna(subset=['next_step_time'])\n",
    "        group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "        return group_df[['client_id', 'visit_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "    # Function to filter out outliers using IQR\n",
    "    def filter_outliers(group_df):\n",
    "        # Convert completion_time to minutes for easier interpretation\n",
    "        group_df['completion_time_minutes'] = group_df['completion_time'].dt.total_seconds() / 60\n",
    "        \n",
    "        # Calculate the IQR (Interquartile Range) for completion time\n",
    "        Q1 = group_df['completion_time_minutes'].quantile(0.25)\n",
    "        Q3 = group_df['completion_time_minutes'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the upper and lower bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter out the outliers based on IQR\n",
    "        filtered_data = group_df[\n",
    "            (group_df['completion_time_minutes'] >= lower_bound) &\n",
    "            (group_df['completion_time_minutes'] <= upper_bound)\n",
    "        ]\n",
    "        return filtered_data\n",
    "\n",
    "    # Apply the function to both the control and test groups\n",
    "    control_group_completion_times = calculate_completion_time_with_visits(control_group)\n",
    "    test_group_completion_times = calculate_completion_time_with_visits(test_group)\n",
    "    \n",
    "    # Filter out outliers from both groups\n",
    "    control_group_filtered = filter_outliers(control_group_completion_times)\n",
    "    test_group_filtered = filter_outliers(test_group_completion_times)\n",
    "    \n",
    "    # Calculate the average completion time in minutes for each process step, after removing outliers\n",
    "    avg_completion_time_control = control_group_filtered.groupby('process_step')['completion_time_minutes'].mean().reset_index()\n",
    "    avg_completion_time_test = test_group_filtered.groupby('process_step')['completion_time_minutes'].mean().reset_index()\n",
    "    \n",
    "    # Display the results for control and test group average completion times\n",
    "    st.subheader(\"Average Completion Time for Control Group (Minutes) - After Outlier Removal\")\n",
    "    st.dataframe(avg_completion_time_control)\n",
    "\n",
    "    st.subheader(\"Average Completion Time for Test Group (Minutes) - After Outlier Removal\")\n",
    "    st.dataframe(avg_completion_time_test)\n",
    "    \n",
    "    # Display comparison of control vs test group average completion times\n",
    "    st.subheader(\"Comparison of Average Completion Time by Process Step\")\n",
    "    comparison_df = pd.merge(avg_completion_time_control, avg_completion_time_test, on='process_step', suffixes=('_control', '_test'))\n",
    "    st.dataframe(comparison_df)\n",
    "\n",
    "    # Optional: You could plot the results for better visualization if desired\n",
    "    # st.bar_chart(comparison_df.set_index('process_step')[['completion_time_minutes_control', 'completion_time_minutes_test']])\n",
    "\n",
    "    # Additional insights and interpretation\n",
    "    st.subheader(\"Insights & Interpretation\")\n",
    "    st.write(\"\"\"\n",
    "    In this section, we can derive insights based on the completion time across different groups and process steps:\n",
    "    \n",
    "    - **Completion Time Analysis**: Are there significant differences in the time it takes for each process step between the Control and Test groups?\n",
    "    - **Outlier Removal**: By removing outliers using the IQR method, we can focus on more representative data for process completion times.\n",
    "    - **Improvement in Test Group**: Does the Test group show faster completion times compared to the Control group after considering the removal of outliers?\n",
    "    \n",
    "    Please review the data and interpret the results to drive business decisions and process improvements.\n",
    "    \"\"\")\n",
    "\n",
    "    # **Process Duration Analysis**: Calculate process duration for start and confirm steps\n",
    "    st.subheader(\"Process Duration Analysis\")\n",
    "\n",
    "    # Filter to get the latest start for each client\n",
    "    starts_only = df[df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Filter to get the last confirmation for each client\n",
    "    confirmation_only = df[df['process_step'] == 'confirm']\n",
    "    latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Merge to have both latest start and confirm per client\n",
    "    latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "    # Calculate process duration for those who completed the process\n",
    "    latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "    # Convert timedelta to seconds for easier manipulation\n",
    "    latest_start_confirms['process_duration_seconds'] = latest_start_confirms['process_duration'].dt.total_seconds()\n",
    "\n",
    "    # Calculate the IQR (Interquartile Range) for process duration\n",
    "    Q1_duration = latest_start_confirms['process_duration_seconds'].quantile(0.25)\n",
    "    Q3_duration = latest_start_confirms['process_duration_seconds'].quantile(0.75)\n",
    "    IQR_duration = Q3_duration - Q1_duration\n",
    "\n",
    "    # Define the upper and lower bounds for outliers in process duration\n",
    "    lower_bound_duration = Q1_duration - 1.5 * IQR_duration\n",
    "    upper_bound_duration = Q3_duration + 1.5 * IQR_duration\n",
    "\n",
    "    # Filter out the outliers based on IQR for process duration\n",
    "    filtered_duration_data = latest_start_confirms[\n",
    "        (latest_start_confirms['process_duration_seconds'] >= lower_bound_duration) &\n",
    "        (latest_start_confirms['process_duration_seconds'] <= upper_bound_duration)\n",
    "    ]\n",
    "\n",
    "    # Convert process_duration back to Timedelta\n",
    "    filtered_duration_data['process_duration'] = pd.to_timedelta(filtered_duration_data['process_duration_seconds'], unit='s')\n",
    "\n",
    "    # Calculate the average process duration again after removing outliers\n",
    "    st.subheader(\"Average Process Duration (Filtered) - After Outlier Removal\")\n",
    "    st.write(f\"Average process duration: {filtered_duration_data['process_duration'].mean()}\")\n",
    "    st.write(f\"Median process duration: {filtered_duration_data['process_duration'].median()}\")\n",
    "    \n",
    "    # Optional: Display filtered duration data\n",
    "    st.subheader(\"Filtered Process Duration Data (Outliers Removed)\")\n",
    "    st.dataframe(filtered_duration_data[['client_id', 'process_duration']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b8b39-13de-4087-b6a3-cc2fe1e80560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Function to calculate counts for z-test\n",
    "def calculate_counts(group):\n",
    "    steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    counts = []  # Store counts as tuples (N_started, N_dropped)\n",
    "    \n",
    "    for i in range(len(steps) - 1):\n",
    "        current_step = steps[i]\n",
    "        next_step = steps[i + 1]\n",
    "        # Total users who started at this step\n",
    "        started = group[group['process_step'] == current_step]['client_id'].nunique()\n",
    "        # Total users who dropped off at this step\n",
    "        reached_next = group[group['process_step'] == next_step]['client_id'].nunique()\n",
    "        dropped = started - reached_next\n",
    "        counts.append((started, dropped))\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Function to perform two-proportion z-test\n",
    "def two_proportion_z_test(n1, x1, n2, x2):\n",
    "    # Calculate proportions\n",
    "    p1 = x1 / n1 if n1 > 0 else 0\n",
    "    p2 = x2 / n2 if n2 > 0 else 0\n",
    "    \n",
    "    # Pooled proportion\n",
    "    p = (x1 + x2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate z-statistic\n",
    "    z = (p1 - p2) / ((p * (1 - p) * (1 / n1 + 1 / n2)) ** 0.5)\n",
    "    \n",
    "    # Calculate two-tailed p-value\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z)))\n",
    "    \n",
    "    return z, p_value\n",
    "\n",
    "# Main function to display the bounce rate analysis page\n",
    "def show_bounce_rate(df):\n",
    "    st.title(\"Bounce Rate Analysis\")\n",
    "\n",
    "    # Ensure that the necessary columns exist in the dataframe\n",
    "    if 'clnt_age' not in df.columns or 'process_step' not in df.columns or 'client_id' not in df.columns:\n",
    "        st.error(\"Required columns ('clnt_age', 'process_step', 'client_id') are missing.\")\n",
    "        return\n",
    "    \n",
    "    # Create age groups based on 'clnt_age'\n",
    "    bins = [0, 30, 40, 50, 100]  # You can adjust the age bins as needed\n",
    "    labels = ['Under 30', '30-39', '40-49', '50 and above']\n",
    "    df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Split the data into Control and Test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "    \n",
    "    # Sort Control and Test groups\n",
    "    control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    \n",
    "    # Calculate the drop-off rates for both Control and Test groups\n",
    "    control_dropoff_rate = calculate_dropoff_rate(control_group_sorted)\n",
    "    test_dropoff_rate = calculate_dropoff_rate(test_group_sorted)\n",
    "\n",
    "    # Display Bounce Rates for Control and Test Groups\n",
    "    st.subheader(\"Bounce Rates for Control and Test Groups (Overall)\")\n",
    "    st.write(\"Control Group Bounce Rates (%):\")\n",
    "    for step, rate in control_dropoff_rate.items():\n",
    "        st.write(f\"{step}: {rate:.2f}%\")\n",
    "    \n",
    "    st.write(\"\\nTest Group Bounce Rates (%):\")\n",
    "    for step, rate in test_dropoff_rate.items():\n",
    "        st.write(f\"{step}: {rate:.2f}%\")\n",
    "    \n",
    "    # Calculate and display drop-off rates by Age Group for Control and Test groups\n",
    "    st.subheader(\"Bounce Rates by Age Group\")\n",
    "\n",
    "    control_dropoff_rate_by_age = calculate_dropoff_rate_by_age(control_group_sorted)\n",
    "    test_dropoff_rate_by_age = calculate_dropoff_rate_by_age(test_group_sorted)\n",
    "\n",
    "    # Display Control group drop-off rates by Age\n",
    "    st.write(\"Control Group Bounce Rates by Age Group:\")\n",
    "    for age_group, rates in control_dropoff_rate_by_age.items():\n",
    "        st.write(f\"Age Group: {age_group}\")\n",
    "        for step, rate in rates.items():\n",
    "            st.write(f\"  {step}: {rate:.2f}%\")\n",
    "    \n",
    "    # Display Test group drop-off rates by Age\n",
    "    st.write(\"Test Group Bounce Rates by Age Group:\")\n",
    "    for age_group, rates in test_dropoff_rate_by_age.items():\n",
    "        st.write(f\"Age Group: {age_group}\")\n",
    "        for step, rate in rates.items():\n",
    "            st.write(f\"  {step}: {rate:.2f}%\")\n",
    "\n",
    "    # **Hypothesis Testing (Z-Test) Section**\n",
    "    st.subheader(\"Hypothesis Test using Z-Test\")\n",
    "    \n",
    "    # Null Hypothesis: H₀ = The bounce rates for the control and test groups are the same for a given step.\n",
    "    # Alternative Hypothesis: H₁ = The bounce rates for the control and test groups are different for a given step.\n",
    "    \n",
    "    st.write(\"\"\"\n",
    "    **Null Hypothesis (H₀)**: The bounce rates for the control and test groups are the same for a given step.  \n",
    "    **Alternative Hypothesis (H₁)**: The bounce rates for the control and test groups are different for a given step.\n",
    "    \"\"\")\n",
    "\n",
    "    # Calculate counts for Control and Test groups\n",
    "    control_counts = calculate_counts(control_group_sorted)\n",
    "    test_counts = calculate_counts(test_group_sorted)\n",
    "\n",
    "    # Perform z-tests for each step and decide on hypothesis\n",
    "    z_test_results = []\n",
    "\n",
    "    steps = ['start', 'step_1', 'step_2', 'step_3']\n",
    "    for i, step in enumerate(steps):\n",
    "        n1, x1 = control_counts[i]  # Control group: (N_started, N_dropped)\n",
    "        n2, x2 = test_counts[i]     # Test group: (N_started, N_dropped)\n",
    "        \n",
    "        # Perform z-test for proportions\n",
    "        z_stat, p_value = two_proportion_z_test(n1, x1, n2, x2)\n",
    "        \n",
    "        # Decide whether to reject the null hypothesis\n",
    "        reject_null = p_value < 0.05\n",
    "        \n",
    "        # Store results\n",
    "        z_test_results.append({\n",
    "            'Step': step,\n",
    "            'Control Bounce Rate (%)': (x1 / n1) * 100 if n1 > 0 else 0,\n",
    "            'Test Bounce Rate (%)': (x2 / n2) * 100 if n2 > 0 else 0,\n",
    "            'Z-Statistic': z_stat,\n",
    "            'P-Value': p_value,\n",
    "            'Reject Null Hypothesis': reject_null\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for display\n",
    "    z_test_results_df = pd.DataFrame(z_test_results)\n",
    "\n",
    "    # Display Z-Test Results\n",
    "    st.write(z_test_results_df)\n",
    "\n",
    "    # Optional: Provide a brief explanation of the Z-Test\n",
    "    st.write(\"\"\"\n",
    "    The Z-Test is used here to test if there is a significant difference between the bounce rates for the control and test groups at each process step.\n",
    "    \n",
    "    - A Z-Statistic closer to 0 indicates that the difference between the two groups is small.\n",
    "    - A p-value below 0.05 suggests that we reject the null hypothesis and conclude that the bounce rates are significantly different.\n",
    "    - If the p-value is greater than 0.05, we fail to reject the null hypothesis, meaning the bounce rates are similar.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447293be-8da0-4b34-9642-58ebc229a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/error_rate.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest, ttest_ind\n",
    "\n",
    "# Function to calculate errors\n",
    "def calculate_errors(group):\n",
    "    group['step_index'] = group['process_step'].map({'start': 0, 'step_1': 1, 'step_2': 2, 'step_3': 3, 'confirm': 4})\n",
    "    group['error'] = group['step_index'].diff().apply(lambda x: x < 0)  # Negative diff indicates a backward step\n",
    "    return group\n",
    "\n",
    "# Function to calculate error rates for both groups\n",
    "def calculate_error_rates(control_group, test_group):\n",
    "    # Calculate errors\n",
    "    control_group = calculate_errors(control_group)\n",
    "    test_group = calculate_errors(test_group)\n",
    "\n",
    "    # Calculate Error Rates\n",
    "    control_error_rate = control_group['error'].mean() * 100\n",
    "    test_error_rate = test_group['error'].mean() * 100\n",
    "\n",
    "    # Error rate difference\n",
    "    error_rate_difference = control_error_rate - test_error_rate  # Difference between control and test error rates\n",
    "    threshold = 5  # 5% threshold for the difference\n",
    "\n",
    "    # Perform hypothesis testing: binomial test\n",
    "    control_errors = control_group['error'].sum()\n",
    "    control_total = len(control_group)\n",
    "    test_errors = test_group['error'].sum()\n",
    "    test_total = len(test_group)\n",
    "\n",
    "    # Perform a one-tailed binomial test\n",
    "    result = binomtest(test_errors, test_total, control_errors / control_total, alternative='less')\n",
    "\n",
    "    # Perform independent t-test for error rates\n",
    "    control_error_rate_values = control_group['error'].astype(int)\n",
    "    test_error_rate_values = test_group['error'].astype(int)\n",
    "\n",
    "    # Perform the independent t-test\n",
    "    t_stat, t_p_value = ttest_ind(control_error_rate_values, test_error_rate_values, equal_var=False, alternative='two-sided')\n",
    "\n",
    "    return {\n",
    "        'control_error_rate': control_error_rate,\n",
    "        'test_error_rate': test_error_rate,\n",
    "        'error_rate_difference': error_rate_difference,\n",
    "        'binomial_p_value': result.pvalue,\n",
    "        't_statistic': t_stat,\n",
    "        't_p_value': t_p_value,\n",
    "    }\n",
    "\n",
    "# Function to display the results\n",
    "def show_error_rate_analysis(df):\n",
    "    st.title(\"Error Rate Hypothesis Testing\")\n",
    "\n",
    "    # Split the data into control and test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    # Calculate error rates and perform hypothesis testing\n",
    "    results = calculate_error_rates(control_group, test_group)\n",
    "\n",
    "    # Display results\n",
    "    st.subheader(\"Error Rates Comparison\")\n",
    "    st.write(f\"Control Group Error Rate: {results['control_error_rate']:.2f}%\")\n",
    "    st.write(f\"Test Group Error Rate: {results['test_error_rate']:.2f}%\")\n",
    "    st.write(f\"Error Rate Difference: {results['error_rate_difference']:.2f}%\")\n",
    "\n",
    "    # Display hypothesis testing results\n",
    "    st.subheader(\"Hypothesis Testing Results\")\n",
    "\n",
    "    # Binomial Test Results\n",
    "    st.write(f\"Binomial Test p-value: {results['binomial_p_value']:.4f}\")\n",
    "    if results['binomial_p_value'] < 0.05:\n",
    "        st.write(\"The test group has significantly lower error rate than the control group (p-value < 0.05).\")\n",
    "    else:\n",
    "        st.write(\"There is no significant difference in error rates between the test and control groups.\")\n",
    "\n",
    "    # T-test Results\n",
    "    st.write(f\"T-test Statistic: {results['t_statistic']:.4f}\")\n",
    "    st.write(f\"T-test p-value: {results['t_p_value']:.4f}\")\n",
    "    if results['t_p_value'] < 0.05:\n",
    "        st.write(\"There is a significant difference in error rates between the control and test groups.\")\n",
    "    else:\n",
    "        st.write(\"There is no significant difference in error rates between the control and test groups.\")\n",
    "\n",
    "    # Conclusion based on practical significance (error rate difference)\n",
    "    st.subheader(\"Practical Significance\")\n",
    "    if results['error_rate_difference'] >= 5:\n",
    "        st.write(\"The test group has at least a 5% lower error rate than the control group, which is practically significant.\")\n",
    "    else:\n",
    "        st.write(\"The error rate difference is less than 5%, which may not be practically significant for making decisions.\")\n",
    "\n",
    "    # Conclusion\n",
    "    st.subheader(\"Conclusion\")\n",
    "    if results['binomial_p_value'] < 0.05 and results['error_rate_difference'] >= 5:\n",
    "        st.write(\"The test group shows both statistical and practical significance. The improvement in error rates may justify action.\")\n",
    "    else:\n",
    "        st.write(\"Although the test group shows statistically significant differences, the practical significance (error rate difference) may not justify making significant changes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519591a6-0cc8-4ffd-976f-ba80bf5761ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee1a38-eb71-4ab2-a21c-9ad96f657e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167da054-1c91-4986-9375-59534cc6378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/display.py\n",
    "import streamlit as st\n",
    "\n",
    "# Function to show an error message\n",
    "def show_error(message: str):\n",
    "    st.error(message)\n",
    "\n",
    "# Function to display a dataframe\n",
    "def display_dataframe(df, rows=5):\n",
    "    if df is not None:\n",
    "        st.dataframe(df.head(rows))\n",
    "    else:\n",
    "        show_error(\"Data is not available.\")\n",
    "\n",
    "# Function to display basic statistics of the dataframe\n",
    "def show_basic_statistics(df):\n",
    "    if df is not None:\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        if not numeric_df.empty:\n",
    "            st.subheader(\"Basic Statistics\")\n",
    "            st.write(numeric_df.describe().T)\n",
    "        else:\n",
    "            show_error(\"No numeric columns found for statistics.\")\n",
    "    else:\n",
    "        show_error(\"Data is not available for statistics.\")\n",
    "\n",
    "# Function to show unique values for categorical columns\n",
    "def show_unique_values(df):\n",
    "    if df is not None:\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if categorical_columns:\n",
    "            for column in categorical_columns:\n",
    "                st.write(f\"Column: {column}\")\n",
    "                st.write(f\"Unique values: {df[column].unique()}\")\n",
    "        else:\n",
    "            show_error(\"No categorical columns found.\")\n",
    "    else:\n",
    "        show_error(\"Data is not available for unique value display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
