{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ebb6c-e765-4bc5-bc7a-872f0fdeb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296aee34-cffc-47c2-928c-64e15b697c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import yaml\n",
    "\n",
    "#with open(\"../config.yaml\", \"r\") as file:\n",
    "#    config = yaml.safe_load(file)\n",
    "\n",
    "#pd.read_csv(config[\"input_data\"][\"file2\"])\n",
    "#df.to_csv(config[\"output_data\"][\"file2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17963993-a2d2-4927-8ce8-7ad43a9b15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3b8ba-7b18-4c4c-97b9-1eb022a241c5",
   "metadata": {},
   "source": [
    "## Clean column name by lower and replace white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292607e-6eca-45c0-8d49-8a045f4af12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sentiment_df\n",
    "# co_ai_adop_df\n",
    "# occu_gro_df\n",
    "# occ_w_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef8a94-dcd8-42b6-aaef-0050b6150985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDDIT COMMENTS AKA ai job sentiment\n",
    "file_p= '../data/raw/reddit_comments_combined.csv'\n",
    "sentiment_df= pd.read_csv(file_p)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8845d5e-d600-48cc-a528-33b3d5e088d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4dbeb3-b6ca-4c1d-8203-7f28d3deb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.columns = sentiment_df.columns.str.replace(' ', '_').str.lower()\n",
    "sentiment_df = sentiment_df.replace(r'\\s+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4564e7-e27a-4d85-bbf2-7a648e4f12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View nulls  Sentiment\n",
    "print(\"Missing values per column:\\n\", sentiment_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ce0d6-2793-4bee-b403-7ff829104dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    " for col in sentiment_df.columns:\n",
    "    if sentiment_df[col].isnull().sum() == 0:\n",
    "        continue  # Skip columns with no missing values\n",
    "    \n",
    "    if sentiment_df[col].dtype == 'object':\n",
    "        mode_val = sentiment_df[col].mode()\n",
    "        if not mode_val.empty:\n",
    "            sentiment_df[col] = sentiment_df[col].fillna(mode_val[0])\n",
    "        else:\n",
    "            sentiment_df[col] = sentiment_df[col].fillna(\"unknown\")  # fallback\n",
    "    else:\n",
    "        mean_val = sentiment_df[col].mean()\n",
    "        sentiment_df[col] = sentiment_df[col].fillna(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008a94b-65c3-49ec-9463-db2bc6f5eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nan values of sentiment\n",
    "sentiment_df['comment_author'] = sentiment_df['comment_author'].fillna('anonymous')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67783f34-8a46-4998-ab53-3b8784826047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "sentiment_df = sentiment_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd30de-f8f1-4b6d-bd8f-26172749e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining nulls:\\n\", sentiment_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a79a2-bd40-4d9b-a367-f6a6f08e21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Drop duplicates and reset index\n",
    "sentiment_df = sentiment_df.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3e31b-c19e-4782-944e-c6204996f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = sentiment_df.drop(['post_id', 'comment_created'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc6c05-645c-43ac-a58d-0949d2cd340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0ebfc-4489-4dc8-9953-9d87c787614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2c4a0-e702-4b80-80ff-9f906e9439b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final shape:\", sentiment_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596b04c-2979-4556-b92f-a7fd6cc2fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['comment_body'] = sentiment_df['comment_body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a16d7-2474-4cdd-805c-eb41c2a2b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec2807-1023-4813-b9fc-460eb91cbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment words list\n",
    "positive_words = {\n",
    "    'safe', 'secure', 'confident', 'optimistic', 'opportunity', 'creative', \n",
    "    'valuable', 'promising', 'empowered', 'supportive', 'hopeful', 'excited','good', 'great', \n",
    "    'helpful', 'smart', 'efficient', 'love', 'amazing', 'brilliant'\n",
    "}\n",
    "\n",
    "negative_words = {\n",
    "    'worried', 'afraid', 'fear', 'replace', 'jobless', 'redundant', \n",
    "    'useless', 'anxious', 'threatened', 'concerned', 'scared', 'depressed',\n",
    "    'bad', 'terrible', 'useless', 'dumb', 'hate', 'annoying', 'slow', 'stupid'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd83a5-bbe5-444f-b16e-9c854f0d24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_spacy(comment):\n",
    "    doc = nlp(comment.lower())\n",
    "    pos_count = sum(token.text in positive_words for token in doc)\n",
    "    neg_count = sum(token.text in negative_words for token in doc)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return 'positive'\n",
    "    elif neg_count > pos_count:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "sentiment_df['sentiment'] = sentiment_df['comment_body'].apply(analyze_sentiment_spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587dabaa-b128-45ec-b19d-da48cf6c2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment_df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a39f9-2251-4562-a349-93eb7a68cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all comments into one string\n",
    "all_text = ' '.join(sentiment_df['comment_body'].dropna().tolist()).lower()\n",
    "\n",
    "# Tokenize with spaCy and filter for actual words (no punctuation/numbers/stop words)\n",
    "#Create a list of \"clean\" words:\n",
    "#    - is_alpha: only keep words (no numbers or punctuation)\n",
    "#    - not token.is_stop: remove common words like \"the\", \"and\", \"is\", etc.\n",
    "#    - token.lemma_: get the base form of each word (e.g., \"working\" â†’ \"work\")\n",
    "doc = nlp(all_text)\n",
    "tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "# Count the top words\n",
    "word_freq = Counter(tokens).most_common(300)\n",
    "\n",
    "# Generate wordcloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(word_freq))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Top 300 Words in Reddit AI Job Comments', fontsize=16)\n",
    "# Displaying the plot\n",
    "plt.savefig(\"../slides/visuals/Top 300 Words in Reddit AI Job Comments.png\", transparent=True, format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc774ef-8a0d-44dd-bda7-290cd504e682",
   "metadata": {},
   "source": [
    "## CLEANING OF EMPLOYMENT PROJECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3063c11-c90f-4f32-81a3-e358ce0812f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f56e9-c1a4-49ca-93f8-b04571cd86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment_projections = pd.read_csv(r'..\\data\\raw\\Employment_projections.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52935c3e-400a-4263-a6c3-6e7f0f635f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Clean column names\n",
    "# Employment_projections.columns = Employment_projections.columns.str.lower().str.replace(\" \", \"_\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe05d51-47b9-45c1-969e-001088756603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. View nulls\n",
    "# print(\"Missing values per column:\\n\", Employment_projections.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cee13d-c0b0-4c33-a889-8d797b337029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582d9fd-59c7-41ba-b9d8-c86be6869fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower().str.replace(\" \", \"_\").str.replace(\",\", \"\").str.strip()\n",
    "# print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdbc07-a5b9-476a-b92d-67e084ae0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['work_experience_in_a_related_occupation'] = df['work_experience_in_a_related_occupation'].fillna('Not Required')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee00ab-6405-45f4-971a-27cd8a19fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['typical_on-the-job_training'] = df['typical_on-the-job_training'].fillna('None')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba39e9a-3da7-4c34-a27b-f3a66607221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment_projections.to_csv(r'..\\data\\clean\\Employment_projection.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b818780-29a9-4d14-bd9b-a8463ffff66c",
   "metadata": {},
   "source": [
    "## CLEANING OF OCCUPATION GROWTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ca668-617e-4945-afa3-dcafa4a38e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[['work_experience_in_a_related_occupation', 'typical_on-the-job_training']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f089cc-78ed-49ff-84b9-824b9b2eec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ data occupation growth\n",
    "import os\n",
    "folder_path = '../data/raw/'\n",
    "matrix_files = [\n",
    "    \"National_Employment_Matrix_IND_31-330.csv\",\n",
    "    \"National_Employment_Matrix_IND_230000.csv\",\n",
    "    \"National_Employment_Matrix_IND_541200.csv\",\n",
    "    \"National_Employment_Matrix_IND_541300.csv\",\n",
    "    \"National_Employment_Matrix_IND_610000.csv\",\n",
    "    \"National_Employment_Matrix_IND_710000.csv\",\n",
    "    \"National_Employment_Matrix_IND_721000.csv\",\n",
    "    \"National_Employment_Matrix_OCC_39-3011.csv\"\n",
    "]\n",
    "\n",
    "# Load and combine all matrix datasets\n",
    "matrix_dfs = []\n",
    "for file in matrix_files:\n",
    "    #path = os.path.join(folder_path, file)\n",
    "    occu_gro_df = pd.read_csv(folder_path + file, on_bad_lines='skip')  # Skip broken lines\n",
    "    occu_gro_df['source_file'] = file  # Track origin\n",
    "    matrix_dfs.append(occu_gro_df)\n",
    "\n",
    "# Merge into one dataframe\n",
    "occu_gro_df = pd.concat(matrix_dfs, ignore_index=True)\n",
    "print(\"Employment matrix shape:\", occu_gro_df.shape)\n",
    "occu_gro_df.head(5)\n",
    "\n",
    "# occu_gro_df= pd.read_csv(r'..\\data\\clean\\occupation_growth.csv')\n",
    "# occu_gro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c39870-3e86-4511-914e-39a17ea69f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean column names\n",
    "occu_gro_df.columns = (\n",
    "    occu_gro_df.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2358de-0d13-4c1e-a105-ed662092131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(occu_gro_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbce0a-6c47-4966-be01-54160ca3296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and reset index\n",
    "occu_gro_df = occu_gro_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e424e-e518-4a4e-85f5-4c67d3d5bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "occu_gro_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613886e-8cc0-41be-b84c-d66ffdb4efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "occu_gro_df = occu_gro_df.loc[:, ['occupation_title', 'occupation_code', '2023_employment', 'projected_2033_employment','employment_percent_change_2023-2033','employment_change_2023-2033']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039ac6c-3ec5-4951-a5a8-d89a0b9414a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "occu_gro_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87de690-3b4c-4a0f-a284-d519efd30fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "occu_gro_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0d666-222a-44d4-bf12-574b62e38526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas and convert to float\n",
    "occu_gro_df['2023_employment'] = occu_gro_df['2023_employment'].str.replace(',', '').astype(float)\n",
    "occu_gro_df['projected_2033_employment'] = occu_gro_df['projected_2033_employment'].str.replace(',', '').astype(float)\n",
    "\n",
    "occu_gro_df['occupation_code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3ba2c-7744-4368-9f66-1fd46b36b686",
   "metadata": {},
   "source": [
    "## CLEANING  OF OCCUPATION WAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303383a2-6c93-465d-b7f3-5b4d4351e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ data occupation wages\n",
    "\n",
    "import csv\n",
    "\n",
    "# Reload the re-uploaded file after reset\n",
    "file_path = '../data/raw/all_data_M_2024.csv'\n",
    "\n",
    "# Attempt to load while skipping problematic lines\n",
    "try:\n",
    "    occ_w_df = pd.read_csv(\n",
    "        file_path,\n",
    "        quoting=csv.QUOTE_MINIMAL,\n",
    "        encoding='utf-8',\n",
    "        on_bad_lines='skip'  # skips problematic lines\n",
    "    )\n",
    "    cleaned_preview = occ_w_df.head()\n",
    "except Exception as e:\n",
    "    cleaned_preview = f\"Error during loading: {e}\"\n",
    "\n",
    "cleaned_preview\n",
    "# Reload the file using semicolon delimiter\n",
    "occ_w_df = pd.read_csv(file_path, delimiter=';', encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "# Show the cleaned preview\n",
    "occ_w_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0991c0-a9e6-48f6-824d-022351f8ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    " #2. Clean column names\n",
    "occ_w_df.columns = (\n",
    "    occ_w_df.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d08105-6a1b-4374-8812-323475a465b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Print missing values for review\n",
    "print(\"Missing values before cleaning:\\n\", occ_w_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af812a-3bba-4144-bfee-ec7773b9551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns (e.g. measure, time_period, etc.)\n",
    "occ_w_df = occ_w_df.loc[:, ~occ_w_df.columns.duplicated()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cd758-006c-4822-9b44-3ee79fd3b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 90% missing values\n",
    "missing_ratio = occ_w_df.isnull().mean()\n",
    "cols_to_drop = missing_ratio[missing_ratio > 0.9].index\n",
    "occ_w_df.drop(columns=cols_to_drop, inplace=True)\n",
    "print(f\"Dropped columns with >90% missing values:\\n{list(cols_to_drop)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff09d8-20df-4553-b495-5cad4d0409db",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_w_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf47950-f115-4821-a6db-45f81a3ebbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "for col in occ_w_df.columns:\n",
    "    if occ_w_df[col].isnull().sum() == 0:\n",
    "        continue\n",
    "    if occ_w_df[col].dtype == 'object':\n",
    "        mode_val = occ_w_df[col].mode()\n",
    "        occ_w_df[col] = occ_w_df[col].fillna(mode_val[0] if not mode_val.empty else \"unknown\")\n",
    "    else:\n",
    "        occ_w_df[col] = occ_w_df[col].fillna(occ_w_df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f1d6a-1ee6-4c0f-8571-0527df0edd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to convert any remaining object columns to numeric\n",
    "for col in occ_w_df.columns:\n",
    "    if occ_w_df[col].dtype == 'object':\n",
    "        occ_w_df[col] = occ_w_df[col].replace(r'[,\\$]', '', regex=True)\n",
    "        try:\n",
    "            occ_w_df[col] = pd.to_numeric(occ_w_df[col])\n",
    "        except:\n",
    "            pass  # leave as object if not convertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44063d-7f3f-49f5-b30b-1312185f791e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Final shape:\", {occ_w_df.shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2407f0-a29d-4ef7-b153-47ef5c77513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_w_df.head(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae0f73-3fc1-4f7a-9f33-f4159831f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_w_df=occ_w_df.loc[:, ['tot_emp', 'h_mean', 'a_mean', 'naics_title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946ac57-cce2-4a38-892a-8a04536ee7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_w_df = occ_w_df.rename(columns={'naics_title':'sector'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f49d6-616d-4600-a07c-dc6797537735",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_w_df['sector'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc99870-0110-44d4-855c-e17359336e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_w_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f2e03-fd6b-43f8-84a9-9ee6fa07485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb13bcb-3d7b-42a7-8137-8819373302f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4a38d3-81b1-4803-8789-e84dfa0335d7",
   "metadata": {},
   "source": [
    "## CLEANING OF COUNTRY  AI ADOPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89995739-7198-4d66-bbda-4f69aea3c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/raw/Oecd.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "co_ai_adop_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "co_ai_adop_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38688ca-a7f0-4736-8e12-99d877ae9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean column names\n",
    "co_ai_adop_df.columns = (\n",
    "    co_ai_adop_df.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .str.replace(\"@\", \"\")\n",
    "    .str.replace(\"+\", \"\")\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d134410-3145-4ff6-af1f-b7fc7e34f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Check for missing values\n",
    "print(\"Missing values before cleaning:\\n\", co_ai_adop_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865f12a-8319-4c7b-955b-aff9ff7479bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop exact duplicate columns\n",
    "co_ai_adop_df = co_ai_adop_df.loc[:, ~co_ai_adop_df.columns.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fd9b6-6ce6-4bdf-bad5-ff4a141355f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with > 90% missing values\n",
    "threshold = 0.9\n",
    "missing_ratio = co_ai_adop_df.isnull().mean()\n",
    "columns_to_drop = missing_ratio[missing_ratio > threshold].index\n",
    "co_ai_adop_df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70daa58-15cb-4b35-82f7-928e111f7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns dropped due to high missing values:\\n\", list(columns_to_drop))\n",
    "\n",
    "# Fill remaining missing values\n",
    "for col in co_ai_adop_df.columns:\n",
    "    if co_ai_adop_df[col].isnull().sum() == 0:\n",
    "        continue\n",
    "    if co_ai_adop_df[col].dtype == 'object':\n",
    "        mode_val = co_ai_adop_df[col].mode()\n",
    "        co_ai_adop_df[col] = co_ai_adop_df[col].fillna(mode_val[0] if not mode_val.empty else 'unknown')\n",
    "    else:\n",
    "        co_ai_adop_df[col] = co_ai_adop_df[col].fillna(co_ai_adop_df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07d56b-292e-4ac5-8f3f-bafdbf45b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = co_ai_adop_df.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521a8b7-d5fa-4fec-a027-fd4a672aa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cleaned Oecd dataset saved. Final shape: {co_ai_adop_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa5315-7912-4ba5-9146-f5f34731b511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5c1bb-a351-487e-9343-c4fbe6666705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8addeb-85bb-455d-b409-53ee7601dbc9",
   "metadata": {},
   "source": [
    "## Formatting data types\n",
    "Dealing with Null values\n",
    "Identify any columns with null or missing values. Identify how many null values each column has. You can use the isnull() function in pandas to find columns with null values.\n",
    "\n",
    "Decide on a strategy for handling the null values. There are several options, including:\n",
    "\n",
    "Drop the rows or columns with null values\n",
    "Fill the null values with a specific value (such as the column mean or median for numerical variables, and mode for categorical variables)\n",
    "Fill the null values with the previous or next value in the column\n",
    "\n",
    "-- Implement your chosen strategy to handle the null values. You can use the fillna() function in pandas to fill null values or dropna() function to drop null values.\n",
    "\n",
    "Verify that your strategy has successfully handled the null values. You can use the isnull() function again to check if there are still null values in the dataset.\n",
    "\n",
    "Remember to document your process and explain your reasoning for choosing a particular strategy for handling null values.\n",
    "\n",
    "After formatting data types, as a last step, convert all the numeric variables to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f0ab-c128-4be9-801a-4acb7667d1fc",
   "metadata": {},
   "source": [
    " ## Dealing with duplicates\n",
    "Use the .duplicated() method to identify any duplicate rows in the dataframe.\n",
    "\n",
    "Decide on a strategy for handling the duplicates. Options include:\n",
    "\n",
    "Dropping all duplicate rows\n",
    "Keeping only the first occurrence of each duplicated row\n",
    "Keeping only the last occurrence of each duplicated row\n",
    "Dropping duplicates based on a subset of columns\n",
    "Dropping duplicates based on a specific column\n",
    "Implement your chosen strategy using the drop_duplicates() function.\n",
    "\n",
    "Verify that your strategy has successfully handled the duplicates by checking for duplicates again using .duplicated().\n",
    "\n",
    "Remember to document your process and explain your reasoning for choosing a particular strategy for handling duplicates.\n",
    "\n",
    "Save the cleaned dataset to a new CSV file.\n",
    "\n",
    "Hint: after dropping duplicates, reset the index to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea7cdb-3b57-4c55-bb03-00e19674d839",
   "metadata": {},
   "source": [
    "## Creating functions on a separate py file\n",
    "Put all the data cleaning and formatting steps into functions, and create a main function that performs all the cleaning and formatting.\n",
    "\n",
    "Write these functions in separate .py file(s). By putting these steps into functions, we can make the code more modular and easier to maintain.\n",
    "\n",
    "Hint: autoreload module is a utility module in Python that allows you to automatically reload modules in the current session when changes are made to the source code. This can be useful in situations where you are actively developing code and want to see the effects of changes you make without having to constantly restart the Python interpreter or Jupyter Notebook kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43968208-c1ae-41bc-bb73-6e18d589bf42",
   "metadata": {},
   "source": [
    "## Analyzing Clean and Formated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb286d6f-10e1-45f0-97e6-60ee76eec4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save reddit csv\n",
    "\n",
    "\n",
    "save_path = '../data/clean/'\n",
    "#os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "sentiment_df.to_csv(save_path + 'ai_job_sentiments.csv', index=False, encoding='utf-8', sep=';')\n",
    "#sentiment_df.to_csv(os.path.join(save_path, 'ai_job_sentiments.csv'), index=False, encoding='utf-8', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4e549-f493-4aee-823d-a18bd27f6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save occupation_growth csv\n",
    "occu_gro_df.to_csv(save_path + 'occupation_growth.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e29a9-874a-4d9d-9c45-9d48fc6e8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save occupation_wages\n",
    "\n",
    "occ_w_df.to_csv(save_path + 'occupation_wages.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b1b84-24a4-4e47-918a-30e52a1b38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save country_ai_adoption\n",
    "co_ai_adop_df.to_csv(save_path + 'country_ai_adoption.csv', index=False, encoding='utf-8', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ab444-c6ea-4324-bf35-2f55cfee8d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
