{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4162e0d-ddcc-4f39-bf60-679ce3914384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c147318-2db5-44ee-92cb-feabcb0bfeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:47:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:46:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_3</td>\n",
       "      <td>2017-04-02 11:23:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-04-02 11:22:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321182</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-03-30 23:59:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321183</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>step_1</td>\n",
       "      <td>2017-03-30 23:58:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321184</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-30 23:58:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321185</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-30 23:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321186</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-31 00:16:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321187 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  \\\n",
       "0          836976             6.0              73.0      60.5  Unknown   \n",
       "1          836976             6.0              73.0      60.5  Unknown   \n",
       "2          836976             6.0              73.0      60.5  Unknown   \n",
       "3          836976             6.0              73.0      60.5  Unknown   \n",
       "4          836976             6.0              73.0      60.5  Unknown   \n",
       "...           ...             ...               ...       ...      ...   \n",
       "321182    7468138            18.0             222.0      61.0   Female   \n",
       "321183    7468138            18.0             222.0      61.0   Female   \n",
       "321184    7468138            18.0             222.0      61.0   Female   \n",
       "321185    7468138            18.0             222.0      61.0   Female   \n",
       "321186    7468138            18.0             222.0      61.0   Female   \n",
       "\n",
       "        num_accts    balance  calls_6_mnth  logons_6_mnth variation  \\\n",
       "0             2.0   45105.30           6.0            9.0      Test   \n",
       "1             2.0   45105.30           6.0            9.0      Test   \n",
       "2             2.0   45105.30           6.0            9.0      Test   \n",
       "3             2.0   45105.30           6.0            9.0      Test   \n",
       "4             2.0   45105.30           6.0            9.0      Test   \n",
       "...           ...        ...           ...            ...       ...   \n",
       "321182        3.0  209278.15           0.0            3.0      Test   \n",
       "321183        3.0  209278.15           0.0            3.0      Test   \n",
       "321184        3.0  209278.15           0.0            3.0      Test   \n",
       "321185        3.0  209278.15           0.0            3.0      Test   \n",
       "321186        3.0  209278.15           0.0            3.0      Test   \n",
       "\n",
       "                   visitor_id                      visit_id process_step  \\\n",
       "0        427070339_1413275162   228976764_46825473280_96584      confirm   \n",
       "1        427070339_1413275162   228976764_46825473280_96584      confirm   \n",
       "2        427070339_1413275162   228976764_46825473280_96584      confirm   \n",
       "3        427070339_1413275162   228976764_46825473280_96584       step_3   \n",
       "4        427070339_1413275162   228976764_46825473280_96584       step_2   \n",
       "...                       ...                           ...          ...   \n",
       "321182  317123960_46820919455  769876461_30381166055_830233       step_2   \n",
       "321183  317123960_46820919455  769876461_30381166055_830233       step_1   \n",
       "321184  317123960_46820919455  769876461_30381166055_830233        start   \n",
       "321185  317123960_46820919455  769876461_30381166055_830233        start   \n",
       "321186  317123960_46820919455  769876461_30381166055_830233        start   \n",
       "\n",
       "                 date_time  \n",
       "0      2017-04-02 11:51:13  \n",
       "1      2017-04-02 11:47:50  \n",
       "2      2017-04-02 11:46:45  \n",
       "3      2017-04-02 11:23:08  \n",
       "4      2017-04-02 11:22:24  \n",
       "...                    ...  \n",
       "321182 2017-03-30 23:59:15  \n",
       "321183 2017-03-30 23:58:51  \n",
       "321184 2017-03-30 23:58:40  \n",
       "321185 2017-03-30 23:55:11  \n",
       "321186 2017-03-31 00:16:12  \n",
       "\n",
       "[321187 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(r'C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\clean\\df_merged.csv')\n",
    "df_2 = pd.read_csv(r'C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\raw\\df_final_web_data_pt_1.txt')\n",
    "df_3 = pd.read_csv(r'C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\raw\\df_final_web_data_pt_2.txt')\n",
    "merged_df = pd.concat([df_2, df_3], axis=0)\n",
    "\n",
    "df_merged = df_1.merge(merged_df, on='client_id', how='inner')\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66783d23-d77a-45dd-9244-313e7bff7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "#Sort control group\n",
    "control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "# Sort test group\n",
    "test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f23331-5339-4bdd-87c7-217ccda4d582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-05-21 11:07:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>step_3</td>\n",
       "      <td>2017-05-21 11:04:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-05-21 11:04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>step_1</td>\n",
       "      <td>2017-05-21 11:03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-05-21 11:03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-05-21 11:02:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  num_accts  \\\n",
       "11    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "12    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "13    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "14    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "15    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "16    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "\n",
       "     balance  calls_6_mnth  logons_6_mnth variation             visitor_id  \\\n",
       "11  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "12  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "13  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "14  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "15  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "16  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "\n",
       "                        visit_id process_step           date_time  \n",
       "11  724930510_65323235593_692754      confirm 2017-05-21 11:07:16  \n",
       "12  724930510_65323235593_692754       step_3 2017-05-21 11:04:53  \n",
       "13  724930510_65323235593_692754       step_2 2017-05-21 11:04:04  \n",
       "14  724930510_65323235593_692754       step_1 2017-05-21 11:03:31  \n",
       "15  724930510_65323235593_692754        start 2017-05-21 11:03:25  \n",
       "16  724930510_65323235593_692754        start 2017-05-21 11:02:21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-05-21 11:03:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  num_accts  \\\n",
       "0    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "\n",
       "    balance  calls_6_mnth  logons_6_mnth variation             visitor_id  \\\n",
       "0  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "\n",
       "                       visit_id process_step           date_time  \n",
       "0  724930510_65323235593_692754        start 2017-05-21 11:03:25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to get latest starts\n",
    "def filter_latest_starts(group_df):\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "    # Merge back to get the full process after the last start\n",
    "    return df_merged.merge(latest_starts[['client_id', 'date_time']], on=['client_id', 'date_time'], how='inner')\n",
    "\n",
    "# Apply to both groups\n",
    "filtered_control = filter_latest_starts(control_group)\n",
    "filtered_test = filter_latest_starts(test_group)\n",
    "\n",
    "#Check if it works\n",
    "client_total_entries = df_merged[df_merged[\"client_id\"] == 2304905]\n",
    "display(client_total_entries)\n",
    "client_last_start = filtered_control[filtered_control['client_id'] == 2304905 ]\n",
    "display(client_last_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f956b873-00f0-4571-8cd8-782f8243b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average duration: 0 days 22:42:16.093893650\n",
      "Duration mode: 0   0 days 00:02:16\n",
      "Name: process_duration, dtype: timedelta64[ns]\n",
      "Duration median: 0 days 00:03:48\n"
     ]
    }
   ],
   "source": [
    "# filter to get the latest start for each client\n",
    "starts_only = df_merged[df_merged['process_step'] == 'start']\n",
    "latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "# filter to get the last confirmation for each client\n",
    "confirmation_only = df_merged[df_merged['process_step'] == 'confirm']\n",
    "latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "# merge to have both latest start and confirm per client\n",
    "# Confirming datetime columns are of Timestamp type in merged DataFrame\n",
    "latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "# calculate process duration for those who completed the process\n",
    "latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "# Scalculate the average duration and compare with mode and mean\n",
    "print(\"Average duration:\", latest_start_confirms['process_duration'].mean())\n",
    "print(\"Duration mode:\", latest_start_confirms['process_duration'].mode())\n",
    "print(\"Duration median:\", latest_start_confirms['process_duration'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e79f5f-e370-4267-a558-4fb4b6d769e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['client_id', 'clnt_tenure_yr', 'clnt_tenure_mnth', 'clnt_age', 'gender',\n",
      "       'num_accts', 'balance', 'calls_6_mnth', 'logons_6_mnth', 'variation',\n",
      "       'visitor_id', 'visit_id', 'process_step', 'date_time'],\n",
      "      dtype='object')\n",
      "Control Group Statistics:\n",
      "Average duration: NaT\n",
      "Duration mode: 0 days 00:00:00\n",
      "Duration median: NaT\n",
      "\n",
      "\n",
      "Test Group Statistics:\n",
      "Average duration: NaT\n",
      "Duration mode: 0 days 00:00:00\n",
      "Duration median: NaT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is of datetime type for both start and confirm stages\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Check the columns in df_merged to verify the structure\n",
    "print(df_merged.columns)\n",
    "\n",
    "# Split the dataset into control and test groups using the 'variation' column\n",
    "control_group = df_merged[df_merged['variation'] == 'control']\n",
    "test_group = df_merged[df_merged['variation'] == 'test']\n",
    "\n",
    "# Function to calculate process duration and statistics\n",
    "def calculate_duration_stats(group_df):\n",
    "    # Filter to get the latest start for each client\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Filter to get the last confirmation for each client\n",
    "    confirmation_only = group_df[group_df['process_step'] == 'confirm']\n",
    "    latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Merge to have both latest start and confirm per client\n",
    "    latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "    # Calculate process duration for those who completed the process\n",
    "    latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "    # Drop rows with NaT values in process_duration\n",
    "    latest_start_confirms = latest_start_confirms.dropna(subset=['process_duration'])\n",
    "\n",
    "    # Convert process_duration to numeric (seconds) for statistical calculations\n",
    "    latest_start_confirms['process_duration_seconds'] = latest_start_confirms['process_duration'].dt.total_seconds()\n",
    "\n",
    "    # Calculate average, mode, and median durations\n",
    "    avg_duration = pd.to_timedelta(latest_start_confirms['process_duration_seconds'].mean(), unit='s')\n",
    "    \n",
    "    # Check if mode is non-empty before accessing the first element\n",
    "    mode_duration = latest_start_confirms['process_duration_seconds'].mode()\n",
    "    if not mode_duration.empty:\n",
    "        mode_duration = pd.to_timedelta(mode_duration[0], unit='s')\n",
    "    else:\n",
    "        mode_duration = pd.to_timedelta(0, unit='s')  # Default to zero if no mode is found\n",
    "    \n",
    "    median_duration = pd.to_timedelta(latest_start_confirms['process_duration_seconds'].median(), unit='s')\n",
    "\n",
    "    return avg_duration, mode_duration, median_duration\n",
    "\n",
    "# Calculate statistics for control group\n",
    "control_avg_duration, control_mode_duration, control_median_duration = calculate_duration_stats(control_group)\n",
    "\n",
    "# Calculate statistics for test group\n",
    "test_avg_duration, test_mode_duration, test_median_duration = calculate_duration_stats(test_group)\n",
    "\n",
    "# Print results for control group\n",
    "print(\"Control Group Statistics:\")\n",
    "print(f\"Average duration: {control_avg_duration}\")\n",
    "print(f\"Duration mode: {control_mode_duration}\")\n",
    "print(f\"Duration median: {control_median_duration}\")\n",
    "print(\"\\n\")  # Add a newline for better separation\n",
    "\n",
    "# Print results for test group\n",
    "print(\"Test Group Statistics:\")\n",
    "print(f\"Average duration: {test_avg_duration}\")\n",
    "print(f\"Duration mode: {test_mode_duration}\")\n",
    "print(f\"Duration median: {test_median_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9c1365-a2d0-44a4-87ef-22ab6894eb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Statistics (With Outliers Removed):\n",
      "Average duration: 0 days 00:04:18.338016588\n",
      "Duration mode: 0 days 00:02:16\n",
      "Duration median: 0 days 00:03:33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Function to calculate process duration and statistics with outlier removal\n",
    "def calculate_duration_stats(group_df):\n",
    "    # Filter to get the latest start for each client\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Filter to get the last confirmation for each client\n",
    "    confirmation_only = group_df[group_df['process_step'] == 'confirm']\n",
    "    latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Merge to have both latest start and confirm per client\n",
    "    latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "    # Calculate process duration for those who completed the process\n",
    "    latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "    # Drop rows with NaT values in process_duration\n",
    "    latest_start_confirms = latest_start_confirms.dropna(subset=['process_duration'])\n",
    "\n",
    "    # Convert process_duration to numeric (seconds) for statistical calculations\n",
    "    latest_start_confirms['process_duration_seconds'] = latest_start_confirms['process_duration'].dt.total_seconds()\n",
    "\n",
    "    # Step 1: Detect outliers using IQR\n",
    "    Q1 = latest_start_confirms['process_duration_seconds'].quantile(0.25)\n",
    "    Q3 = latest_start_confirms['process_duration_seconds'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the outlier bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Step 2: Filter out the outliers\n",
    "    filtered_df = latest_start_confirms[(latest_start_confirms['process_duration_seconds'] >= lower_bound) & \n",
    "                                        (latest_start_confirms['process_duration_seconds'] <= upper_bound)]\n",
    "\n",
    "    # Step 3: Calculate the average, mode, and median durations\n",
    "    avg_duration = pd.to_timedelta(filtered_df['process_duration_seconds'].mean(), unit='s')\n",
    "    \n",
    "    # Check if mode is non-empty before accessing the first element\n",
    "    mode_duration = filtered_df['process_duration_seconds'].mode()\n",
    "    if not mode_duration.empty:\n",
    "        mode_duration = pd.to_timedelta(mode_duration[0], unit='s')\n",
    "    else:\n",
    "        mode_duration = pd.to_timedelta(0, unit='s')  # Default to zero if no mode is found\n",
    "    \n",
    "    median_duration = pd.to_timedelta(filtered_df['process_duration_seconds'].median(), unit='s')\n",
    "\n",
    "    return avg_duration, mode_duration, median_duration\n",
    "\n",
    "# Calculate statistics for the entire dataset (with outlier removal)\n",
    "avg_duration, mode_duration, median_duration = calculate_duration_stats(df_merged)\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Statistics (With Outliers Removed):\")\n",
    "print(f\"Average duration: {avg_duration}\")\n",
    "print(f\"Duration mode: {mode_duration}\")\n",
    "print(f\"Duration median: {median_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a8e55a-f80e-4da8-8ade-e2b293c145c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Group Statistics (With Outliers Removed):\n",
      "Average duration: NaT\n",
      "Duration mode: 0 days 00:00:00\n",
      "Duration median: NaT\n",
      "\n",
      "Test Group Statistics (With Outliers Removed):\n",
      "Average duration: NaT\n",
      "Duration mode: 0 days 00:00:00\n",
      "Duration median: NaT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Function to calculate process duration and statistics with outlier removal for each group\n",
    "def calculate_duration_stats(group_df):\n",
    "    # Filter to get the latest start for each client\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Filter to get the last confirmation for each client\n",
    "    confirmation_only = group_df[group_df['process_step'] == 'confirm']\n",
    "    latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Merge to have both latest start and confirm per client\n",
    "    latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "    # Calculate process duration for those who completed the process\n",
    "    latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "    # Drop rows with NaT values in process_duration\n",
    "    latest_start_confirms = latest_start_confirms.dropna(subset=['process_duration'])\n",
    "\n",
    "    # Convert process_duration to numeric (seconds) for statistical calculations\n",
    "    latest_start_confirms['process_duration_seconds'] = latest_start_confirms['process_duration'].dt.total_seconds()\n",
    "\n",
    "    # Step 1: Detect outliers using IQR\n",
    "    Q1 = latest_start_confirms['process_duration_seconds'].quantile(0.25)\n",
    "    Q3 = latest_start_confirms['process_duration_seconds'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the outlier bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Step 2: Filter out the outliers\n",
    "    filtered_df = latest_start_confirms[(latest_start_confirms['process_duration_seconds'] >= lower_bound) & \n",
    "                                        (latest_start_confirms['process_duration_seconds'] <= upper_bound)]\n",
    "\n",
    "    # Step 3: Calculate the average, mode, and median durations\n",
    "    avg_duration = pd.to_timedelta(filtered_df['process_duration_seconds'].mean(), unit='s')\n",
    "    \n",
    "    # Check if mode is non-empty before accessing the first element\n",
    "    mode_duration = filtered_df['process_duration_seconds'].mode()\n",
    "    if not mode_duration.empty:\n",
    "        mode_duration = pd.to_timedelta(mode_duration[0], unit='s')\n",
    "    else:\n",
    "        mode_duration = pd.to_timedelta(0, unit='s')  # Default to zero if no mode is found\n",
    "    \n",
    "    median_duration = pd.to_timedelta(filtered_df['process_duration_seconds'].median(), unit='s')\n",
    "\n",
    "    return avg_duration, mode_duration, median_duration\n",
    "\n",
    "# Split the dataset into control and test groups based on the 'variation' column\n",
    "control_group = df_merged[df_merged['variation'] == 'control']\n",
    "test_group = df_merged[df_merged['variation'] == 'test']\n",
    "\n",
    "# Calculate statistics for control group\n",
    "control_avg_duration, control_mode_duration, control_median_duration = calculate_duration_stats(control_group)\n",
    "\n",
    "# Calculate statistics for test group\n",
    "test_avg_duration, test_mode_duration, test_median_duration = calculate_duration_stats(test_group)\n",
    "\n",
    "# Print results for control group\n",
    "print(\"Control Group Statistics (With Outliers Removed):\")\n",
    "print(f\"Average duration: {control_avg_duration}\")\n",
    "print(f\"Duration mode: {control_mode_duration}\")\n",
    "print(f\"Duration median: {control_median_duration}\")\n",
    "\n",
    "# Print results for test group\n",
    "print(\"\\nTest Group Statistics (With Outliers Removed):\")\n",
    "print(f\"Average duration: {test_avg_duration}\")\n",
    "print(f\"Duration mode: {test_mode_duration}\")\n",
    "print(f\"Duration median: {test_median_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea6b9e0-a2dd-4d62-a8f9-5cd2e78cc254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        client_id process_step           date_time      next_step_time  \\\n",
      "255388        555        start 2017-04-15 12:57:56 2017-04-15 12:58:03   \n",
      "255387        555       step_1 2017-04-15 12:58:03 2017-04-15 12:58:35   \n",
      "255386        555       step_2 2017-04-15 12:58:35 2017-04-15 13:00:14   \n",
      "255385        555       step_3 2017-04-15 13:00:14 2017-04-15 13:00:34   \n",
      "9749          647        start 2017-04-12 15:41:28 2017-04-12 15:41:35   \n",
      "...           ...          ...                 ...                 ...   \n",
      "310089    9999729        start 2017-05-08 16:08:25 2017-05-08 16:08:30   \n",
      "310088    9999729       step_1 2017-05-08 16:08:30 2017-05-08 16:08:40   \n",
      "310087    9999729       step_2 2017-05-08 16:08:40 2017-05-08 16:09:19   \n",
      "310086    9999729       step_3 2017-05-08 16:09:19 2017-05-08 16:09:40   \n",
      "51309     9999832        start 2017-05-16 16:46:03 2017-05-16 16:46:11   \n",
      "\n",
      "       completion_time  \n",
      "255388 0 days 00:00:07  \n",
      "255387 0 days 00:00:32  \n",
      "255386 0 days 00:01:39  \n",
      "255385 0 days 00:00:20  \n",
      "9749   0 days 00:00:07  \n",
      "...                ...  \n",
      "310089 0 days 00:00:05  \n",
      "310088 0 days 00:00:10  \n",
      "310087 0 days 00:00:39  \n",
      "310086 0 days 00:00:21  \n",
      "51309  0 days 00:00:08  \n",
      "\n",
      "[150820 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_19528\\940740622.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time(test_group)\n",
    "\n",
    "# Display the results\n",
    "print(test_group_completion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5d587e-b2ce-4b5f-86d4-9d2a7d34a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  process_step           completion_time\n",
      "0      confirm 4 days 01:21:08.606944811\n",
      "1        start 1 days 03:42:14.554952723\n",
      "2       step_1 0 days 11:55:38.837214944\n",
      "3       step_2 0 days 05:53:23.973691999\n",
      "4       step_3 0 days 09:09:14.330464854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_19528\\706682172.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time(test_group)\n",
    "\n",
    "# Group by process_step and calculate the average completion time for each step\n",
    "average_completion_times = test_group_completion_times.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Display the average completion times\n",
    "print(average_completion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc05d58-60fd-4414-9b2e-935af009842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Completion Times (Z-score method):\n",
      "  process_step           completion_time\n",
      "0      confirm 1 days 13:37:49.074216524\n",
      "1        start 0 days 07:03:57.558949063\n",
      "2       step_1 0 days 03:05:12.195431402\n",
      "3       step_2 0 days 01:31:49.043561607\n",
      "4       step_3 0 days 02:34:01.954097962\n",
      "\n",
      "Average Completion Times (IQR method):\n",
      "  process_step           completion_time\n",
      "0      confirm 0 days 00:01:13.727586206\n",
      "1        start 0 days 00:00:30.646762285\n",
      "2       step_1 0 days 00:00:39.209762958\n",
      "3       step_2 0 days 00:01:07.075556187\n",
      "4       step_3 0 days 00:01:04.705025631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_19528\\3773383250.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time(test_group)\n",
    "\n",
    "# Function to remove outliers using Z-score method\n",
    "def remove_outliers_zscore(df, column_name, threshold=3):\n",
    "    # Calculate the Z-scores\n",
    "    z_scores = (df[column_name] - df[column_name].mean()) / df[column_name].std()\n",
    "    \n",
    "    # Filter out rows where Z-score is greater than the threshold (indicating an outlier)\n",
    "    return df[np.abs(z_scores) <= threshold]\n",
    "\n",
    "# Function to remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, column_name):\n",
    "    # Calculate the IQR\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Filter out rows that are below Q1 - 1.5*IQR or above Q3 + 1.5*IQR\n",
    "    return df[(df[column_name] >= Q1 - 1.5 * IQR) & (df[column_name] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "test_group_no_outliers_zscore = remove_outliers_zscore(test_group_completion_times, 'completion_time')\n",
    "\n",
    "# Alternatively, remove outliers using IQR\n",
    "test_group_no_outliers_iqr = remove_outliers_iqr(test_group_completion_times, 'completion_time')\n",
    "\n",
    "# Calculate average completion time after removing outliers (Z-score)\n",
    "average_completion_times_zscore = test_group_no_outliers_zscore.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Calculate average completion time after removing outliers (IQR)\n",
    "average_completion_times_iqr = test_group_no_outliers_iqr.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Display the results\n",
    "print(\"Average Completion Times (Z-score method):\")\n",
    "print(average_completion_times_zscore)\n",
    "\n",
    "print(\"\\nAverage Completion Times (IQR method):\")\n",
    "print(average_completion_times_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f16f5b-8fd9-4809-9bc6-8a571016e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group\n",
      "Under 30        120.000000\n",
      "30-39           155.000000\n",
      "40-49           190.000000\n",
      "50 and above    253.333333\n",
      "Name: process_duration, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_19528\\302951963.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  avg_process_duration = df_merged.groupby('age_group')['process_duration'].mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame df_merged with 'clnt_age' and 'process_duration' columns\n",
    "# This would typically already exist in your data\n",
    "data = {\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52],  # Example ages\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240]  # Example process durations (in seconds)\n",
    "}\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Calculate the average process duration for each age group\n",
    "# Assuming 'process_duration' is in seconds, we can calculate the average for each age group\n",
    "avg_process_duration = df_merged.groupby('age_group')['process_duration'].mean()\n",
    "\n",
    "# Display the average process duration for each age group\n",
    "print(avg_process_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "063920a3-3471-430a-a28c-239b61ecef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group\n",
      "Under 30        0.008372\n",
      "30-39           0.006458\n",
      "40-49           0.005278\n",
      "50 and above    0.003957\n",
      "Name: process_rate, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_19528\\2818000591.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  avg_process_rate = df_merged.groupby('age_group')['process_rate'].mean()\n"
     ]
    }
   ],
   "source": [
    "# Assuming process_rate is inversely related to process_duration (work per unit time)\n",
    "df_merged['process_rate'] = 1 / df_merged['process_duration']\n",
    "\n",
    "# Calculate the average process rate for each age group\n",
    "avg_process_rate = df_merged.groupby('age_group')['process_rate'].mean()\n",
    "\n",
    "# Display the average process rate for each age group\n",
    "print(avg_process_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "642b6cda-bf7e-4377-ba02-371a24de372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Completion Times (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:30\n",
      "       start 0 days 00:02:35\n",
      "      step_1 0 days 00:03:55\n",
      "      step_2 0 days 00:03:00\n",
      "      step_3 0 days 00:03:05\n",
      "\n",
      "Average Completion Times (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:30\n",
      "       start 0 days 00:02:35\n",
      "      step_1 0 days 00:03:55\n",
      "      step_2 0 days 00:03:00\n",
      "      step_3 0 days 00:03:05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'group': ['test', 'test', 'test', 'test', 'test', 'test', 'test', 'test', 'test', 'test'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define function to calculate average process time for each step\n",
    "def calculate_average_times(df):\n",
    "    avg_times = df.groupby('process_step')['process_duration'].mean().reset_index()\n",
    "    avg_times['completion_time'] = pd.to_timedelta(avg_times['process_duration'], unit='s')\n",
    "    return avg_times[['process_step', 'completion_time']]\n",
    "\n",
    "# Calculate average completion times without outliers\n",
    "avg_completion_times = calculate_average_times(df_merged)\n",
    "\n",
    "# Outlier Detection using Z-score method (without scipy)\n",
    "def detect_outliers_zscore(df, column_name, threshold=3):\n",
    "    mean = df[column_name].mean()\n",
    "    std_dev = df[column_name].std()\n",
    "    z_scores = (df[column_name] - mean) / std_dev\n",
    "    return df[np.abs(z_scores) > threshold]\n",
    "\n",
    "# IQR method for outlier detection\n",
    "def detect_outliers_iqr(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column_name] < (Q1 - 1.5 * IQR)) | (df[column_name] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Remove outliers using Z-score and IQR methods\n",
    "df_merged_zscore = df_merged[~df_merged['process_duration'].isin(detect_outliers_zscore(df_merged, 'process_duration')['process_duration'])]\n",
    "df_merged_iqr = df_merged[~df_merged['process_duration'].isin(detect_outliers_iqr(df_merged, 'process_duration')['process_duration'])]\n",
    "\n",
    "# Calculate the average times after removing outliers for Z-score method\n",
    "avg_times_zscore = calculate_average_times(df_merged_zscore)\n",
    "\n",
    "# Calculate the average times after removing outliers for IQR method\n",
    "avg_times_iqr = calculate_average_times(df_merged_iqr)\n",
    "\n",
    "# Format the output as requested\n",
    "print(\"Average Completion Times (Z-score method):\")\n",
    "print(avg_times_zscore.to_string(index=False))\n",
    "\n",
    "print(\"\\nAverage Completion Times (IQR method):\")\n",
    "print(avg_times_iqr.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aeeb743-1bf5-4b0d-a998-cb7629140a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Group Within-Visit Completion Rates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_step</th>\n",
       "      <th>completed_visits</th>\n",
       "      <th>started_visits</th>\n",
       "      <th>completion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confirm</td>\n",
       "      <td>16039</td>\n",
       "      <td>30903</td>\n",
       "      <td>51.901110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>step_1</td>\n",
       "      <td>23541</td>\n",
       "      <td>30903</td>\n",
       "      <td>76.177070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>step_2</td>\n",
       "      <td>20131</td>\n",
       "      <td>30903</td>\n",
       "      <td>65.142543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>step_3</td>\n",
       "      <td>18293</td>\n",
       "      <td>30903</td>\n",
       "      <td>59.194900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  process_step  completed_visits  started_visits  completion_rate\n",
       "0      confirm             16039           30903        51.901110\n",
       "1       step_1             23541           30903        76.177070\n",
       "2       step_2             20131           30903        65.142543\n",
       "3       step_3             18293           30903        59.194900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Group Within-Visit Completion Rates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_step</th>\n",
       "      <th>completed_visits</th>\n",
       "      <th>started_visits</th>\n",
       "      <th>completion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confirm</td>\n",
       "      <td>21725</td>\n",
       "      <td>33142</td>\n",
       "      <td>65.551264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>step_1</td>\n",
       "      <td>28273</td>\n",
       "      <td>33142</td>\n",
       "      <td>85.308672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>step_2</td>\n",
       "      <td>24493</td>\n",
       "      <td>33142</td>\n",
       "      <td>73.903204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>step_3</td>\n",
       "      <td>22180</td>\n",
       "      <td>33142</td>\n",
       "      <td>66.924145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  process_step  completed_visits  started_visits  completion_rate\n",
       "0      confirm             21725           33142        65.551264\n",
       "1       step_1             28273           33142        85.308672\n",
       "2       step_2             24493           33142        73.903204\n",
       "3       step_3             22180           33142        66.924145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#completion rate based on visit_id\n",
    "def calculate_within_visit_completion_rate(group):\n",
    "    # Total unique visits that started\n",
    "    started_visits = group[group['process_step'] == 'start']['visit_id'].nunique()\n",
    "\n",
    "    # Unique visits that completed each step\n",
    "    completed_visits = (\n",
    "        group[group['process_step'] != 'start']\n",
    "        .groupby('process_step')['visit_id']\n",
    "        .nunique()\n",
    "        .reset_index(name='completed_visits')\n",
    "    )\n",
    "\n",
    "    # Add the total started visits as a constant column\n",
    "    completed_visits['started_visits'] = started_visits\n",
    "\n",
    "    # Calculate the completion rate\n",
    "    completed_visits['completion_rate'] = (\n",
    "        completed_visits['completed_visits'] / completed_visits['started_visits']\n",
    "    ) * 100\n",
    "\n",
    "    return completed_visits\n",
    "\n",
    "# Calculate completion rates for the control and test groups\n",
    "control_completion_rate = calculate_within_visit_completion_rate(control_group_sorted)\n",
    "test_completion_rate = calculate_within_visit_completion_rate(test_group_sorted)\n",
    "\n",
    "# Display the results\n",
    "print(\"Control Group Within-Visit Completion Rates:\")\n",
    "display(control_completion_rate)\n",
    "\n",
    "print(\"Test Group Within-Visit Completion Rates:\")\n",
    "display(test_completion_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c50303-5e76-4b97-8a02-4623b0f4526d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66480ddd-cffd-4662-aad4-6cae8ecfc10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
