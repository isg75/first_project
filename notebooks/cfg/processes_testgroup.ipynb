{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4162e0d-ddcc-4f39-bf60-679ce3914384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c147318-2db5-44ee-92cb-feabcb0bfeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:47:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:46:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_3</td>\n",
       "      <td>2017-04-02 11:23:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-04-02 11:22:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321182</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-03-30 23:59:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321183</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>step_1</td>\n",
       "      <td>2017-03-30 23:58:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321184</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-30 23:58:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321185</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-30 23:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321186</th>\n",
       "      <td>7468138</td>\n",
       "      <td>18.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209278.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>317123960_46820919455</td>\n",
       "      <td>769876461_30381166055_830233</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-31 00:16:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321187 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  \\\n",
       "0          836976             6.0              73.0      60.5  Unknown   \n",
       "1          836976             6.0              73.0      60.5  Unknown   \n",
       "2          836976             6.0              73.0      60.5  Unknown   \n",
       "3          836976             6.0              73.0      60.5  Unknown   \n",
       "4          836976             6.0              73.0      60.5  Unknown   \n",
       "...           ...             ...               ...       ...      ...   \n",
       "321182    7468138            18.0             222.0      61.0   Female   \n",
       "321183    7468138            18.0             222.0      61.0   Female   \n",
       "321184    7468138            18.0             222.0      61.0   Female   \n",
       "321185    7468138            18.0             222.0      61.0   Female   \n",
       "321186    7468138            18.0             222.0      61.0   Female   \n",
       "\n",
       "        num_accts    balance  calls_6_mnth  logons_6_mnth variation  \\\n",
       "0             2.0   45105.30           6.0            9.0      Test   \n",
       "1             2.0   45105.30           6.0            9.0      Test   \n",
       "2             2.0   45105.30           6.0            9.0      Test   \n",
       "3             2.0   45105.30           6.0            9.0      Test   \n",
       "4             2.0   45105.30           6.0            9.0      Test   \n",
       "...           ...        ...           ...            ...       ...   \n",
       "321182        3.0  209278.15           0.0            3.0      Test   \n",
       "321183        3.0  209278.15           0.0            3.0      Test   \n",
       "321184        3.0  209278.15           0.0            3.0      Test   \n",
       "321185        3.0  209278.15           0.0            3.0      Test   \n",
       "321186        3.0  209278.15           0.0            3.0      Test   \n",
       "\n",
       "                   visitor_id                      visit_id process_step  \\\n",
       "0        427070339_1413275162   228976764_46825473280_96584      confirm   \n",
       "1        427070339_1413275162   228976764_46825473280_96584      confirm   \n",
       "2        427070339_1413275162   228976764_46825473280_96584      confirm   \n",
       "3        427070339_1413275162   228976764_46825473280_96584       step_3   \n",
       "4        427070339_1413275162   228976764_46825473280_96584       step_2   \n",
       "...                       ...                           ...          ...   \n",
       "321182  317123960_46820919455  769876461_30381166055_830233       step_2   \n",
       "321183  317123960_46820919455  769876461_30381166055_830233       step_1   \n",
       "321184  317123960_46820919455  769876461_30381166055_830233        start   \n",
       "321185  317123960_46820919455  769876461_30381166055_830233        start   \n",
       "321186  317123960_46820919455  769876461_30381166055_830233        start   \n",
       "\n",
       "                 date_time  \n",
       "0      2017-04-02 11:51:13  \n",
       "1      2017-04-02 11:47:50  \n",
       "2      2017-04-02 11:46:45  \n",
       "3      2017-04-02 11:23:08  \n",
       "4      2017-04-02 11:22:24  \n",
       "...                    ...  \n",
       "321182 2017-03-30 23:59:15  \n",
       "321183 2017-03-30 23:58:51  \n",
       "321184 2017-03-30 23:58:40  \n",
       "321185 2017-03-30 23:55:11  \n",
       "321186 2017-03-31 00:16:12  \n",
       "\n",
       "[321187 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(r'C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\clean\\df_merged.csv')\n",
    "df_2 = pd.read_csv(r'C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\raw\\df_final_web_data_pt_1.txt')\n",
    "df_3 = pd.read_csv(r'C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\raw\\df_final_web_data_pt_2.txt')\n",
    "merged_df = pd.concat([df_2, df_3], axis=0)\n",
    "\n",
    "df_merged = df_1.merge(merged_df, on='client_id', how='inner')\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66783d23-d77a-45dd-9244-313e7bff7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "#Sort control group\n",
    "control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "# Sort test group\n",
    "test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13f23331-5339-4bdd-87c7-217ccda4d582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-05-21 11:07:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>step_3</td>\n",
       "      <td>2017-05-21 11:04:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-05-21 11:04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>step_1</td>\n",
       "      <td>2017-05-21 11:03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-05-21 11:03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-05-21 11:02:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  num_accts  \\\n",
       "11    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "12    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "13    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "14    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "15    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "16    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "\n",
       "     balance  calls_6_mnth  logons_6_mnth variation             visitor_id  \\\n",
       "11  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "12  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "13  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "14  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "15  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "16  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "\n",
       "                        visit_id process_step           date_time  \n",
       "11  724930510_65323235593_692754      confirm 2017-05-21 11:07:16  \n",
       "12  724930510_65323235593_692754       step_3 2017-05-21 11:04:53  \n",
       "13  724930510_65323235593_692754       step_2 2017-05-21 11:04:04  \n",
       "14  724930510_65323235593_692754       step_1 2017-05-21 11:03:31  \n",
       "15  724930510_65323235593_692754        start 2017-05-21 11:03:25  \n",
       "16  724930510_65323235593_692754        start 2017-05-21 11:02:21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2304905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110860.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>336210275_56978226960</td>\n",
       "      <td>724930510_65323235593_692754</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-05-21 11:03:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  num_accts  \\\n",
       "0    2304905             7.0              94.0      58.0  Unknown        2.0   \n",
       "\n",
       "    balance  calls_6_mnth  logons_6_mnth variation             visitor_id  \\\n",
       "0  110860.3           6.0            9.0   Control  336210275_56978226960   \n",
       "\n",
       "                       visit_id process_step           date_time  \n",
       "0  724930510_65323235593_692754        start 2017-05-21 11:03:25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to get latest starts\n",
    "def filter_latest_starts(group_df):\n",
    "    starts_only = group_df[group_df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "    # Merge back to get the full process after the last start\n",
    "    return df_merged.merge(latest_starts[['client_id', 'date_time']], on=['client_id', 'date_time'], how='inner')\n",
    "\n",
    "# Apply to both groups\n",
    "filtered_control = filter_latest_starts(control_group)\n",
    "filtered_test = filter_latest_starts(test_group)\n",
    "\n",
    "#Check if it works\n",
    "client_total_entries = df_merged[df_merged[\"client_id\"] == 2304905]\n",
    "display(client_total_entries)\n",
    "client_last_start = filtered_control[filtered_control['client_id'] == 2304905 ]\n",
    "display(client_last_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e63d45d-aa2f-4427-9f79-e2942d47c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clnt_age     age_group\n",
      "0      60.5  50 and above\n",
      "1      60.5  50 and above\n",
      "2      60.5  50 and above\n",
      "3      60.5  50 and above\n",
      "4      60.5  50 and above\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_merged already contains the relevant columns, including 'clnt_age'\n",
    "# Define the bins and labels for age groups\n",
    "bins = [0, 30, 40, 50, 100]  # These bins categorize ages into 4 groups\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Apply the bins to categorize the 'clnt_age' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Display the first few rows of the DataFrame to check the new 'age_group' column\n",
    "print(df_merged[['clnt_age', 'age_group']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e444a36-41c4-4a76-a0f3-0afee5ce2cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>clnt_tenure_yr</th>\n",
       "      <th>clnt_tenure_mnth</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_accts</th>\n",
       "      <th>balance</th>\n",
       "      <th>calls_6_mnth</th>\n",
       "      <th>logons_6_mnth</th>\n",
       "      <th>variation</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>process_step</th>\n",
       "      <th>date_time</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:51:13</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:47:50</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>confirm</td>\n",
       "      <td>2017-04-02 11:46:45</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_3</td>\n",
       "      <td>2017-04-02 11:23:08</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_2</td>\n",
       "      <td>2017-04-02 11:22:24</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>step_1</td>\n",
       "      <td>2017-04-02 11:21:38</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>228976764_46825473280_96584</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-04-02 11:21:28</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>104438405_2368283624_817211</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-29 11:02:44</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>104438405_2368283624_817211</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-29 11:01:40</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>836976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45105.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>427070339_1413275162</td>\n",
       "      <td>104438405_2368283624_817211</td>\n",
       "      <td>start</td>\n",
       "      <td>2017-03-29 10:59:43</td>\n",
       "      <td>50 and above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age   gender  num_accts  \\\n",
       "0     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "1     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "2     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "3     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "4     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "5     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "6     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "7     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "8     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "9     836976             6.0              73.0      60.5  Unknown        2.0   \n",
       "\n",
       "   balance  calls_6_mnth  logons_6_mnth variation            visitor_id  \\\n",
       "0  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "1  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "2  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "3  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "4  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "5  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "6  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "7  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "8  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "9  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
       "\n",
       "                      visit_id process_step           date_time     age_group  \n",
       "0  228976764_46825473280_96584      confirm 2017-04-02 11:51:13  50 and above  \n",
       "1  228976764_46825473280_96584      confirm 2017-04-02 11:47:50  50 and above  \n",
       "2  228976764_46825473280_96584      confirm 2017-04-02 11:46:45  50 and above  \n",
       "3  228976764_46825473280_96584       step_3 2017-04-02 11:23:08  50 and above  \n",
       "4  228976764_46825473280_96584       step_2 2017-04-02 11:22:24  50 and above  \n",
       "5  228976764_46825473280_96584       step_1 2017-04-02 11:21:38  50 and above  \n",
       "6  228976764_46825473280_96584        start 2017-04-02 11:21:28  50 and above  \n",
       "7  104438405_2368283624_817211        start 2017-03-29 11:02:44  50 and above  \n",
       "8  104438405_2368283624_817211        start 2017-03-29 11:01:40  50 and above  \n",
       "9  104438405_2368283624_817211        start 2017-03-29 10:59:43  50 and above  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd771-3ace-4fe3-98ed-57fe4fd0d221",
   "metadata": {},
   "source": [
    "**Test group Completion Times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ea6b9e0-a2dd-4d62-a8f9-5cd2e78cc254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\1581245714.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        client_id process_step           date_time      next_step_time  \\\n",
      "255388        555        start 2017-04-15 12:57:56 2017-04-15 12:58:03   \n",
      "255387        555       step_1 2017-04-15 12:58:03 2017-04-15 12:58:35   \n",
      "255386        555       step_2 2017-04-15 12:58:35 2017-04-15 13:00:14   \n",
      "255385        555       step_3 2017-04-15 13:00:14 2017-04-15 13:00:34   \n",
      "9749          647        start 2017-04-12 15:41:28 2017-04-12 15:41:35   \n",
      "...           ...          ...                 ...                 ...   \n",
      "310089    9999729        start 2017-05-08 16:08:25 2017-05-08 16:08:30   \n",
      "310088    9999729       step_1 2017-05-08 16:08:30 2017-05-08 16:08:40   \n",
      "310087    9999729       step_2 2017-05-08 16:08:40 2017-05-08 16:09:19   \n",
      "310086    9999729       step_3 2017-05-08 16:09:19 2017-05-08 16:09:40   \n",
      "51309     9999832        start 2017-05-16 16:46:03 2017-05-16 16:46:11   \n",
      "\n",
      "       completion_time  \n",
      "255388 0 days 00:00:07  \n",
      "255387 0 days 00:00:32  \n",
      "255386 0 days 00:01:39  \n",
      "255385 0 days 00:00:20  \n",
      "9749   0 days 00:00:07  \n",
      "...                ...  \n",
      "310089 0 days 00:00:05  \n",
      "310088 0 days 00:00:10  \n",
      "310087 0 days 00:00:39  \n",
      "310086 0 days 00:00:21  \n",
      "51309  0 days 00:00:08  \n",
      "\n",
      "[150820 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time(test_group)\n",
    "\n",
    "# Display the results\n",
    "print(test_group_completion_times)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "test_group_completion_times.to_csv('test_group_completion_times.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "472eb943-8465-4ab8-928d-a8328c2ed96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\3051574082.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        client_id process_step           date_time      next_step_time  \\\n",
      "302407       1028        start 2017-04-08 18:51:28 2017-04-08 18:52:17   \n",
      "302406       1028       step_1 2017-04-08 18:52:17 2017-04-08 18:53:20   \n",
      "302405       1028       step_1 2017-04-08 18:53:20 2017-04-08 18:53:29   \n",
      "302404       1028       step_2 2017-04-08 18:53:29 2017-04-08 18:58:04   \n",
      "302403       1028       step_3 2017-04-08 18:58:04 2017-04-08 18:59:55   \n",
      "...           ...          ...                 ...                 ...   \n",
      "142953    9998346       step_1 2017-03-29 15:29:55 2017-03-29 15:30:11   \n",
      "142952    9998346       step_2 2017-03-29 15:30:11 2017-03-29 15:30:25   \n",
      "142951    9998346       step_3 2017-03-29 15:30:25 2017-03-29 15:37:28   \n",
      "142948    9998346       step_3 2017-03-29 15:37:28 2017-03-29 15:37:28   \n",
      "142949    9998346      confirm 2017-03-29 15:37:28 2017-03-29 15:37:28   \n",
      "\n",
      "       completion_time  \n",
      "302407 0 days 00:00:49  \n",
      "302406 0 days 00:01:03  \n",
      "302405 0 days 00:00:09  \n",
      "302404 0 days 00:04:35  \n",
      "302403 0 days 00:01:51  \n",
      "...                ...  \n",
      "142953 0 days 00:00:16  \n",
      "142952 0 days 00:00:14  \n",
      "142951 0 days 00:07:03  \n",
      "142948 0 days 00:00:00  \n",
      "142949 0 days 00:00:00  \n",
      "\n",
      "[119882 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is in datetime format\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Filter for the control group only\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "control_group = control_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the control group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the control group\n",
    "control_group_completion_times = calculate_completion_time(control_group)\n",
    "\n",
    "# Display the results\n",
    "print(control_group_completion_times)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "control_group_completion_times.to_csv('control_group_completion_times.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba06163e-2d90-419d-ba8d-ff5fd9c08134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  process_step           completion_time\n",
      "0      confirm 3 days 15:56:20.739548169\n",
      "1        start 1 days 10:11:09.560954126\n",
      "2       step_1 0 days 15:58:33.285787190\n",
      "3       step_2 0 days 09:34:49.364355884\n",
      "4       step_3 0 days 16:39:25.669293174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\3832345684.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Filter for the control group only\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "control_group = control_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the control group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the control group\n",
    "control_group_completion_times = calculate_completion_time(control_group)\n",
    "\n",
    "# Group by process_step and calculate the average completion time for each step\n",
    "average_completion_times = control_group_completion_times.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Display the average completion times\n",
    "print(average_completion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e5d587e-b2ce-4b5f-86d4-9d2a7d34a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  process_step           completion_time\n",
      "0      confirm 4 days 01:21:08.606944811\n",
      "1        start 1 days 03:42:14.554952723\n",
      "2       step_1 0 days 11:55:38.837214944\n",
      "3       step_2 0 days 05:53:23.973691999\n",
      "4       step_3 0 days 09:09:14.330464854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\706682172.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')  # Coerce invalid formats to NaT\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time(test_group)\n",
    "\n",
    "# Group by process_step and calculate the average completion time for each step\n",
    "average_completion_times = test_group_completion_times.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Display the average completion times\n",
    "print(average_completion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12bff825-4e22-4464-9762-946d4b53faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Completion Times (Z-score method):\n",
      "  process_step           completion_time\n",
      "0      confirm 1 days 15:03:32.220572057\n",
      "1        start 0 days 08:37:48.481388120\n",
      "2       step_1 0 days 04:07:12.722905358\n",
      "3       step_2 0 days 02:07:03.572315953\n",
      "4       step_3 0 days 04:14:04.067482055\n",
      "\n",
      "Average Completion Times (IQR method):\n",
      "  process_step           completion_time\n",
      "0      confirm 0 days 00:00:46.759779614\n",
      "1        start 0 days 00:00:32.379614568\n",
      "2       step_1 0 days 00:00:33.825110701\n",
      "3       step_2 0 days 00:01:11.280119052\n",
      "4       step_3 0 days 00:01:15.113086530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\349647999.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the control group only\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "control_group = control_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the control group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the control group\n",
    "control_group_completion_times = calculate_completion_time(control_group)\n",
    "\n",
    "# Function to remove outliers using Z-score method\n",
    "def remove_outliers_zscore(df, column_name, threshold=3):\n",
    "    # Calculate the Z-scores\n",
    "    z_scores = (df[column_name] - df[column_name].mean()) / df[column_name].std()\n",
    "    \n",
    "    # Filter out rows where Z-score is greater than the threshold (indicating an outlier)\n",
    "    return df[np.abs(z_scores) <= threshold]\n",
    "\n",
    "# Function to remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, column_name):\n",
    "    # Calculate the IQR\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Filter out rows that are below Q1 - 1.5*IQR or above Q3 + 1.5*IQR\n",
    "    return df[(df[column_name] >= Q1 - 1.5 * IQR) & (df[column_name] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "control_group_no_outliers_zscore = remove_outliers_zscore(control_group_completion_times, 'completion_time')\n",
    "\n",
    "# Alternatively, remove outliers using IQR\n",
    "control_group_no_outliers_iqr = remove_outliers_iqr(control_group_completion_times, 'completion_time')\n",
    "\n",
    "# Calculate average completion time after removing outliers (Z-score)\n",
    "average_completion_times_zscore = control_group_no_outliers_zscore.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Calculate average completion time after removing outliers (IQR)\n",
    "average_completion_times_iqr = control_group_no_outliers_iqr.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Display the results\n",
    "print(\"Average Completion Times (Z-score method):\")\n",
    "print(average_completion_times_zscore)\n",
    "\n",
    "print(\"\\nAverage Completion Times (IQR method):\")\n",
    "print(average_completion_times_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bc05d58-60fd-4414-9b2e-935af009842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Completion Times (Z-score method):\n",
      "  process_step           completion_time\n",
      "0      confirm 1 days 13:37:49.074216524\n",
      "1        start 0 days 07:03:57.558949063\n",
      "2       step_1 0 days 03:05:12.195431402\n",
      "3       step_2 0 days 01:31:49.043561607\n",
      "4       step_3 0 days 02:34:01.954097962\n",
      "\n",
      "Average Completion Times (IQR method):\n",
      "  process_step           completion_time\n",
      "0      confirm 0 days 00:01:13.727586206\n",
      "1        start 0 days 00:00:30.646762285\n",
      "2       step_1 0 days 00:00:39.209762958\n",
      "3       step_2 0 days 00:01:07.075556187\n",
      "4       step_3 0 days 00:01:04.705025631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\3773383250.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure 'date_time' is of datetime type\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group\n",
    "def calculate_completion_time(group_df):\n",
    "    # Create a new column to store the completion time for each step\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Only keep rows where the next step exists (i.e., not NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    return group_df[['client_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time(test_group)\n",
    "\n",
    "# Function to remove outliers using Z-score method\n",
    "def remove_outliers_zscore(df, column_name, threshold=3):\n",
    "    # Calculate the Z-scores\n",
    "    z_scores = (df[column_name] - df[column_name].mean()) / df[column_name].std()\n",
    "    \n",
    "    # Filter out rows where Z-score is greater than the threshold (indicating an outlier)\n",
    "    return df[np.abs(z_scores) <= threshold]\n",
    "\n",
    "# Function to remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, column_name):\n",
    "    # Calculate the IQR\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Filter out rows that are below Q1 - 1.5*IQR or above Q3 + 1.5*IQR\n",
    "    return df[(df[column_name] >= Q1 - 1.5 * IQR) & (df[column_name] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "test_group_no_outliers_zscore = remove_outliers_zscore(test_group_completion_times, 'completion_time')\n",
    "\n",
    "# Alternatively, remove outliers using IQR\n",
    "test_group_no_outliers_iqr = remove_outliers_iqr(test_group_completion_times, 'completion_time')\n",
    "\n",
    "# Calculate average completion time after removing outliers (Z-score)\n",
    "average_completion_times_zscore = test_group_no_outliers_zscore.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Calculate average completion time after removing outliers (IQR)\n",
    "average_completion_times_iqr = test_group_no_outliers_iqr.groupby('process_step')['completion_time'].mean().reset_index()\n",
    "\n",
    "# Display the results\n",
    "print(\"Average Completion Times (Z-score method):\")\n",
    "print(average_completion_times_zscore)\n",
    "\n",
    "print(\"\\nAverage Completion Times (IQR method):\")\n",
    "print(average_completion_times_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1f16f5b-8fd9-4809-9bc6-8a571016e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Process Rate for Test Group:\n",
      "age_group\n",
      "Under 30        0.008372\n",
      "30-39           0.006250\n",
      "40-49           0.005000\n",
      "50 and above         NaN\n",
      "Name: process_rate, dtype: float64\n",
      "\n",
      "Average Process Rate for Control Group:\n",
      "age_group\n",
      "Under 30             NaN\n",
      "30-39           0.006667\n",
      "40-49           0.005556\n",
      "50 and above    0.003957\n",
      "Name: process_rate, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\3737360533.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  avg_process_rate_test = test_group.groupby('age_group')['process_rate'].mean()\n",
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\3737360533.py:29: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  avg_process_rate_control = control_group.groupby('age_group')['process_rate'].mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame df_merged with 'clnt_age', 'process_duration', and 'variation' columns\n",
    "data = {\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52],  # Example ages\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # Example process durations (in seconds)\n",
    "    'variation': ['Test', 'Control', 'Test', 'Control', 'Test', 'Control', 'Test', 'Control', 'Test', 'Control']  # Example group labels\n",
    "}\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Calculate process rate (1 / process_duration) for each row\n",
    "df_merged['process_rate'] = 1 / df_merged['process_duration']\n",
    "\n",
    "# Filter for Test and Control groups\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "\n",
    "# Calculate the average process rate for each age group within the Test group\n",
    "avg_process_rate_test = test_group.groupby('age_group')['process_rate'].mean()\n",
    "\n",
    "# Calculate the average process rate for each age group within the Control group\n",
    "avg_process_rate_control = control_group.groupby('age_group')['process_rate'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Average Process Rate for Test Group:\")\n",
    "print(avg_process_rate_test)\n",
    "\n",
    "print(\"\\nAverage Process Rate for Control Group:\")\n",
    "print(avg_process_rate_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "642b6cda-bf7e-4377-ba02-371a24de372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Group Average Completion Times (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "       start 0 days 00:02:40\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Test Group Average Completion Times (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "       start 0 days 00:02:40\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Control Group Average Completion Times (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "       start 0 days 00:02:30\n",
      "      step_1 0 days 00:03:20\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Control Group Average Completion Times (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "       start 0 days 00:02:30\n",
      "      step_1 0 days 00:03:20\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:02:10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with 'group' for Test and Control\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'group': ['Control', 'Control', 'Control', 'Control', 'Control', 'Test', 'Test', 'Test', 'Test', 'Test'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate average process time for each step\n",
    "def calculate_average_times(df):\n",
    "    avg_times = df.groupby('process_step')['process_duration'].mean().reset_index()\n",
    "    avg_times['completion_time'] = pd.to_timedelta(avg_times['process_duration'], unit='s')\n",
    "    return avg_times[['process_step', 'completion_time']]\n",
    "\n",
    "# Outlier Detection using Z-score method (without scipy)\n",
    "def detect_outliers_zscore(df, column_name, threshold=3):\n",
    "    mean = df[column_name].mean()\n",
    "    std_dev = df[column_name].std()\n",
    "    z_scores = (df[column_name] - mean) / std_dev\n",
    "    return df[np.abs(z_scores) > threshold]\n",
    "\n",
    "# IQR method for outlier detection\n",
    "def detect_outliers_iqr(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column_name] < (Q1 - 1.5 * IQR)) | (df[column_name] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Function to apply the analysis for both Test and Control groups\n",
    "def analyze_groups(df):\n",
    "    # Separate the data by group (Test and Control)\n",
    "    test_group = df[df['group'] == 'Test']\n",
    "    control_group = df[df['group'] == 'Control']\n",
    "\n",
    "    # Remove outliers using Z-score and IQR methods for Test group\n",
    "    test_group_zscore = test_group[~test_group['process_duration'].isin(detect_outliers_zscore(test_group, 'process_duration')['process_duration'])]\n",
    "    test_group_iqr = test_group[~test_group['process_duration'].isin(detect_outliers_iqr(test_group, 'process_duration')['process_duration'])]\n",
    "\n",
    "    # Remove outliers using Z-score and IQR methods for Control group\n",
    "    control_group_zscore = control_group[~control_group['process_duration'].isin(detect_outliers_zscore(control_group, 'process_duration')['process_duration'])]\n",
    "    control_group_iqr = control_group[~control_group['process_duration'].isin(detect_outliers_iqr(control_group, 'process_duration')['process_duration'])]\n",
    "\n",
    "    # Calculate the average times for each group after removing outliers\n",
    "    avg_times_test_zscore = calculate_average_times(test_group_zscore)\n",
    "    avg_times_test_iqr = calculate_average_times(test_group_iqr)\n",
    "\n",
    "    avg_times_control_zscore = calculate_average_times(control_group_zscore)\n",
    "    avg_times_control_iqr = calculate_average_times(control_group_iqr)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Test Group Average Completion Times (Z-score method):\")\n",
    "    print(avg_times_test_zscore.to_string(index=False))\n",
    "\n",
    "    print(\"\\nTest Group Average Completion Times (IQR method):\")\n",
    "    print(avg_times_test_iqr.to_string(index=False))\n",
    "\n",
    "    print(\"\\nControl Group Average Completion Times (Z-score method):\")\n",
    "    print(avg_times_control_zscore.to_string(index=False))\n",
    "\n",
    "    print(\"\\nControl Group Average Completion Times (IQR method):\")\n",
    "    print(avg_times_control_iqr.to_string(index=False))\n",
    "\n",
    "# Call the function to analyze both groups\n",
    "analyze_groups(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1fed98c-31d1-440e-8bd5-d8a5377a3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Test Group...\n",
      "\n",
      "Test Group Average Completion Times (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "       start 0 days 00:02:30\n",
      "      step_1 0 days 00:03:20\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Test Group Average Completion Times (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "       start 0 days 00:02:30\n",
      "      step_1 0 days 00:03:20\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: Under 30 and Gender: Male (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: Under 30 and Gender: Male (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: Under 30 and Gender: Female (Z-score method):\n",
      "process_step completion_time\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: Under 30 and Gender: Female (IQR method):\n",
      "process_step completion_time\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 30-39 and Gender: Male (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 30-39 and Gender: Male (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 30-39 and Gender: Female (Z-score method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:30\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 30-39 and Gender: Female (IQR method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:30\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 40-49 and Gender: Male (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 40-49 and Gender: Male (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 40-49 and Gender: Female (Z-score method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:03:20\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 40-49 and Gender: Female (IQR method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:03:20\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 50 and above and Gender: Male (Z-score method):\n",
      "process_step completion_time\n",
      "      step_2 0 days 00:04:10\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 50 and above and Gender: Male (IQR method):\n",
      "process_step completion_time\n",
      "      step_2 0 days 00:04:10\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 50 and above and Gender: Female (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Test Group - Average Completion Times for Age Group: 50 and above and Gender: Female (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Processing Control Group...\n",
      "\n",
      "Control Group Average Completion Times (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "       start 0 days 00:02:40\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Control Group Average Completion Times (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "       start 0 days 00:02:40\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: Under 30 and Gender: Male (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: Under 30 and Gender: Male (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: Under 30 and Gender: Female (Z-score method):\n",
      "process_step completion_time\n",
      "      step_2 0 days 00:01:50\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: Under 30 and Gender: Female (IQR method):\n",
      "process_step completion_time\n",
      "      step_2 0 days 00:01:50\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 30-39 and Gender: Male (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 30-39 and Gender: Male (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 30-39 and Gender: Female (Z-score method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:40\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 30-39 and Gender: Female (IQR method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:40\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 40-49 and Gender: Male (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 40-49 and Gender: Male (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 40-49 and Gender: Female (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 40-49 and Gender: Female (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 50 and above and Gender: Male (Z-score method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:04:30\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 50 and above and Gender: Male (IQR method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:04:30\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 50 and above and Gender: Female (Z-score method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n",
      "\n",
      "Control Group - Average Completion Times for Age Group: 50 and above and Gender: Female (IQR method):\n",
      "Empty DataFrame\n",
      "Columns: [process_step, completion_time]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with 'clnt_age' and 'gender' columns added\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'group': ['Test', 'Test', 'Test', 'Test', 'Test', 'Control', 'Control', 'Control', 'Control', 'Control'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # process duration in seconds\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52],  # Client age\n",
    "    'gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male']  # Client gender\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Define function to calculate average process time for each step\n",
    "def calculate_average_times(df):\n",
    "    avg_times = df.groupby('process_step')['process_duration'].mean().reset_index()\n",
    "    avg_times['completion_time'] = pd.to_timedelta(avg_times['process_duration'], unit='s')\n",
    "    return avg_times[['process_step', 'completion_time']]\n",
    "\n",
    "# Outlier Detection using Z-score method (without scipy)\n",
    "def detect_outliers_zscore(df, column_name, threshold=3):\n",
    "    mean = df[column_name].mean()\n",
    "    std_dev = df[column_name].std()\n",
    "    z_scores = (df[column_name] - mean) / std_dev\n",
    "    return df[np.abs(z_scores) > threshold]\n",
    "\n",
    "# IQR method for outlier detection\n",
    "def detect_outliers_iqr(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column_name] < (Q1 - 1.5 * IQR)) | (df[column_name] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Function to process each group (Test or Control)\n",
    "def process_group(df, group_name):\n",
    "    group_df = df[df['group'] == group_name]\n",
    "\n",
    "    # Remove outliers using Z-score and IQR methods\n",
    "    group_zscore = group_df[~group_df['process_duration'].isin(detect_outliers_zscore(group_df, 'process_duration')['process_duration'])]\n",
    "    group_iqr = group_df[~group_df['process_duration'].isin(detect_outliers_iqr(group_df, 'process_duration')['process_duration'])]\n",
    "\n",
    "    # Calculate the average times after filtering out outliers\n",
    "    avg_times_zscore = calculate_average_times(group_zscore)\n",
    "    avg_times_iqr = calculate_average_times(group_iqr)\n",
    "\n",
    "    return avg_times_zscore, avg_times_iqr\n",
    "\n",
    "# Function to calculate average times by age group and gender\n",
    "def calculate_avg_times_by_age_gender(df, group_name, age_group, gender):\n",
    "    # Filter the dataframe based on group, age group, and gender\n",
    "    filtered_df = df[(df['group'] == group_name) & (df['age_group'] == age_group) & (df['gender'] == gender)]\n",
    "    \n",
    "    # Calculate the average process times for the filtered dataframe\n",
    "    avg_times = calculate_average_times(filtered_df)\n",
    "    \n",
    "    return avg_times\n",
    "\n",
    "# Function to analyze both Test and Control groups and display results\n",
    "def analyze_groups(df):\n",
    "    # Process both Test and Control groups\n",
    "    for group_name in df['group'].unique():\n",
    "        print(f\"\\nProcessing {group_name} Group...\")\n",
    "\n",
    "        # Process the group to remove outliers and calculate average times\n",
    "        avg_times_zscore, avg_times_iqr = process_group(df, group_name)\n",
    "\n",
    "        print(f\"\\n{group_name} Group Average Completion Times (Z-score method):\")\n",
    "        print(avg_times_zscore.to_string(index=False))\n",
    "\n",
    "        print(f\"\\n{group_name} Group Average Completion Times (IQR method):\")\n",
    "        print(avg_times_iqr.to_string(index=False))\n",
    "\n",
    "        # Now calculate and display average times for each age group and gender\n",
    "        for age_group in df['age_group'].unique():\n",
    "            for gender in df['gender'].unique():\n",
    "                print(f\"\\n{group_name} Group - Average Completion Times for Age Group: {age_group} and Gender: {gender} (Z-score method):\")\n",
    "                avg_times_zscore_by_age_gender = calculate_avg_times_by_age_gender(df, group_name, age_group, gender)\n",
    "                print(avg_times_zscore_by_age_gender.to_string(index=False))\n",
    "\n",
    "                print(f\"\\n{group_name} Group - Average Completion Times for Age Group: {age_group} and Gender: {gender} (IQR method):\")\n",
    "                avg_times_iqr_by_age_gender = calculate_avg_times_by_age_gender(df, group_name, age_group, gender)\n",
    "                print(avg_times_iqr_by_age_gender.to_string(index=False))\n",
    "\n",
    "# Call the function to analyze both groups\n",
    "analyze_groups(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a63ac6b4-b701-4f8d-a7d6-225a80ae863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Completion Times for Age Group: Under 30 (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Average Completion Times for Age Group: Under 30 (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Average Completion Times for Age Group: Under 30 (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Average Completion Times for Age Group: Under 30 (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:02:00\n",
      "      step_2 0 days 00:01:50\n",
      "      step_3 0 days 00:02:10\n",
      "\n",
      "Average Completion Times for Age Group: 30-39 (Z-score method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:35\n",
      "\n",
      "Average Completion Times for Age Group: 30-39 (IQR method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:35\n",
      "\n",
      "Average Completion Times for Age Group: 30-39 (Z-score method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:35\n",
      "\n",
      "Average Completion Times for Age Group: 30-39 (IQR method):\n",
      "process_step completion_time\n",
      "       start 0 days 00:02:35\n",
      "\n",
      "Average Completion Times for Age Group: 40-49 (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "      step_1 0 days 00:03:20\n",
      "\n",
      "Average Completion Times for Age Group: 40-49 (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "      step_1 0 days 00:03:20\n",
      "\n",
      "Average Completion Times for Age Group: 40-49 (Z-score method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "      step_1 0 days 00:03:20\n",
      "\n",
      "Average Completion Times for Age Group: 40-49 (IQR method):\n",
      "process_step completion_time\n",
      "     confirm 0 days 00:03:00\n",
      "      step_1 0 days 00:03:20\n",
      "\n",
      "Average Completion Times for Age Group: 50 and above (Z-score method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Average Completion Times for Age Group: 50 and above (IQR method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Average Completion Times for Age Group: 50 and above (Z-score method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:04:00\n",
      "\n",
      "Average Completion Times for Age Group: 50 and above (IQR method):\n",
      "process_step completion_time\n",
      "      step_1 0 days 00:04:30\n",
      "      step_2 0 days 00:04:10\n",
      "      step_3 0 days 00:04:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with 'clnt_age' and 'gender' columns added\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'group': ['test', 'test', 'test', 'test', 'test', 'test', 'test', 'test', 'test', 'test'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # process duration in seconds\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52],  # Client age\n",
    "    'gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male']  # Client gender\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Define function to calculate average process time for each step\n",
    "def calculate_average_times(df):\n",
    "    avg_times = df.groupby('process_step')['process_duration'].mean().reset_index()\n",
    "    avg_times['completion_time'] = pd.to_timedelta(avg_times['process_duration'], unit='s')\n",
    "    return avg_times[['process_step', 'completion_time']]\n",
    "\n",
    "# Outlier Detection using Z-score method (without scipy)\n",
    "def detect_outliers_zscore(df, column_name, threshold=3):\n",
    "    mean = df[column_name].mean()\n",
    "    std_dev = df[column_name].std()\n",
    "    z_scores = (df[column_name] - mean) / std_dev\n",
    "    return df[np.abs(z_scores) > threshold]\n",
    "\n",
    "# IQR method for outlier detection\n",
    "def detect_outliers_iqr(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column_name] < (Q1 - 1.5 * IQR)) | (df[column_name] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# Filter out outliers using Z-score and IQR methods\n",
    "df_merged_zscore = df_merged[~df_merged['process_duration'].isin(detect_outliers_zscore(df_merged, 'process_duration')['process_duration'])]\n",
    "df_merged_iqr = df_merged[~df_merged['process_duration'].isin(detect_outliers_iqr(df_merged, 'process_duration')['process_duration'])]\n",
    "\n",
    "# Group by 'age_group' and 'gender', and calculate the average process times\n",
    "def calculate_avg_times_by_age_gender(df, age_group):\n",
    "    filtered_df = df[(df['age_group'] == age_group)]\n",
    "    \n",
    "    # Calculate the average times after filtering by age group and gender\n",
    "    avg_times = calculate_average_times(filtered_df)\n",
    "    \n",
    "    return avg_times\n",
    "\n",
    "# Iterate over all age groups and genders to display the results\n",
    "for age_group in df_merged['age_group'].unique():\n",
    "    for gender in df_merged['gender'].unique():\n",
    "        print(f\"\\nAverage Completion Times for Age Group: {age_group} (Z-score method):\")\n",
    "        avg_times_zscore = calculate_avg_times_by_age_gender(df_merged_zscore, age_group)\n",
    "        print(avg_times_zscore.to_string(index=False))\n",
    "\n",
    "        print(f\"\\nAverage Completion Times for Age Group: {age_group} (IQR method):\")\n",
    "        avg_times_iqr = calculate_avg_times_by_age_gender(df_merged_iqr, age_group)\n",
    "        print(avg_times_iqr.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82de1c78-1308-4b0d-812d-38e37e487535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age_group process_step           date_time      next_step_time  \\\n",
      "4      Under 30       step_3 2024-11-20 09:30:00 2024-11-20 10:00:00   \n",
      "0      Under 30      confirm 2024-11-20 10:00:00 2024-11-21 09:20:00   \n",
      "1         30-39        start 2024-11-20 08:00:00 2024-11-21 08:10:00   \n",
      "2         40-49       step_1 2024-11-20 08:15:00 2024-11-21 10:00:00   \n",
      "3  50 and above       step_2 2024-11-20 09:00:00 2024-11-21 08:40:00   \n",
      "7  50 and above       step_1 2024-11-21 08:40:00 2024-11-21 09:45:00   \n",
      "\n",
      "  completion_time  \n",
      "4 0 days 00:30:00  \n",
      "0 0 days 23:20:00  \n",
      "1 1 days 00:10:00  \n",
      "2 1 days 01:45:00  \n",
      "3 0 days 23:40:00  \n",
      "7 0 days 01:05:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\1790549215.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_df['next_step_time'] = group_df.groupby('age_group')['date_time'].shift(-1)\n",
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\1790549215.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data (as defined in your context)\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'variation': ['Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # process duration in seconds\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52]  # Client age\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Ensure date_time is in datetime format\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by age_group and date_time to ensure chronological order of events\n",
    "test_group = test_group.sort_values(by=['age_group', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the test group by age group\n",
    "def calculate_completion_time_by_age_group(group_df):\n",
    "    # Create a new column to store the next step time\n",
    "    group_df['next_step_time'] = group_df.groupby('age_group')['date_time'].shift(-1)\n",
    "    \n",
    "    # Drop rows where the next step does not exist (i.e., NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between the current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    # Only keep relevant columns\n",
    "    return group_df[['age_group', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_completion_times = calculate_completion_time_by_age_group(test_group)\n",
    "\n",
    "# Display the results\n",
    "print(test_group_completion_times)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "test_group_completion_times.to_csv('test_group_completion_times_by_age_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9c3baae-56f6-41bd-92ff-223d4395ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age_group process_step           date_time      next_step_time  \\\n",
      "4      Under 30       step_3 2024-11-20 09:30:00 2024-11-20 10:00:00   \n",
      "0      Under 30      confirm 2024-11-20 10:00:00 2024-11-21 09:20:00   \n",
      "1         30-39        start 2024-11-20 08:00:00 2024-11-21 08:10:00   \n",
      "2         40-49       step_1 2024-11-20 08:15:00 2024-11-21 10:00:00   \n",
      "3  50 and above       step_2 2024-11-20 09:00:00 2024-11-21 08:40:00   \n",
      "7  50 and above       step_1 2024-11-21 08:40:00 2024-11-21 09:45:00   \n",
      "\n",
      "  completion_time  \n",
      "4 0 days 00:30:00  \n",
      "0 0 days 23:20:00  \n",
      "1 1 days 00:10:00  \n",
      "2 1 days 01:45:00  \n",
      "3 0 days 23:40:00  \n",
      "7 0 days 01:05:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\2458080096.py:39: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_df['next_step_time'] = group_df.groupby('age_group')['date_time'].shift(-1)\n",
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\2458080096.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data (same as before)\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'variation': ['Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # process duration in seconds\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52]  # Client age\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Ensure date_time is in datetime format\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the control group only\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "\n",
    "# Sort by age_group and date_time to ensure chronological order of events\n",
    "control_group = control_group.sort_values(by=['age_group', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step in the control group by age group\n",
    "def calculate_completion_time_by_age_group(group_df):\n",
    "    # Create a new column to store the next step time\n",
    "    group_df['next_step_time'] = group_df.groupby('age_group')['date_time'].shift(-1)\n",
    "    \n",
    "    # Drop rows where the next step does not exist (i.e., NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the completion time as the time difference between the current and next step\n",
    "    group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    # Only keep relevant columns\n",
    "    return group_df[['age_group', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "# Apply the function to the control group\n",
    "control_group_completion_times = calculate_completion_time_by_age_group(control_group)\n",
    "\n",
    "# Display the results\n",
    "print(control_group_completion_times)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "control_group_completion_times.to_csv('control_group_completion_times_by_age_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0896a00-e2bd-41ce-a274-f4a52db892c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id     age_group process_step           date_time  \\\n",
      "1          1         30-39        start 2024-11-20 08:00:00   \n",
      "2          1         40-49       step_1 2024-11-20 08:15:00   \n",
      "3          1  50 and above       step_2 2024-11-20 09:00:00   \n",
      "4          1      Under 30       step_3 2024-11-20 09:30:00   \n",
      "6          2         30-39        start 2024-11-21 08:10:00   \n",
      "7          2  50 and above       step_1 2024-11-21 08:40:00   \n",
      "8          2      Under 30       step_2 2024-11-21 09:20:00   \n",
      "9          2  50 and above       step_3 2024-11-21 09:45:00   \n",
      "\n",
      "       next_step_time visit_time_diff  \n",
      "1 2024-11-20 08:15:00 0 days 00:15:00  \n",
      "2 2024-11-20 09:00:00 0 days 00:45:00  \n",
      "3 2024-11-20 09:30:00 0 days 00:30:00  \n",
      "4 2024-11-20 10:00:00 0 days 00:30:00  \n",
      "6 2024-11-21 08:40:00 0 days 00:30:00  \n",
      "7 2024-11-21 09:20:00 0 days 00:40:00  \n",
      "8 2024-11-21 09:45:00 0 days 00:25:00  \n",
      "9 2024-11-21 10:00:00 0 days 00:15:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\2880829352.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['visit_time_diff'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data (same as before)\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'variation': ['Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # process duration in seconds\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52]  # Client age\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Ensure date_time is in datetime format\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the control group only\n",
    "control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of visits\n",
    "control_group = control_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step and client visit\n",
    "def calculate_completion_time_by_visit(group_df):\n",
    "    # Create a new column to store the next step time\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Drop rows where the next step does not exist (i.e., NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the time between consecutive visits (this is the time difference between each visit)\n",
    "    group_df['visit_time_diff'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    # Only keep relevant columns\n",
    "    return group_df[['client_id', 'age_group', 'process_step', 'date_time', 'next_step_time', 'visit_time_diff']]\n",
    "\n",
    "# Apply the function to the control group\n",
    "control_group_visit_times = calculate_completion_time_by_visit(control_group)\n",
    "\n",
    "# Display the results\n",
    "print(control_group_visit_times)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "control_group_visit_times.to_csv('control_group_visit_times.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96ee9323-6725-410e-957d-fd161ab1d19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id     age_group process_step           date_time  \\\n",
      "1          1         30-39        start 2024-11-20 08:00:00   \n",
      "2          1         40-49       step_1 2024-11-20 08:15:00   \n",
      "3          1  50 and above       step_2 2024-11-20 09:00:00   \n",
      "4          1      Under 30       step_3 2024-11-20 09:30:00   \n",
      "6          2         30-39        start 2024-11-21 08:10:00   \n",
      "7          2  50 and above       step_1 2024-11-21 08:40:00   \n",
      "8          2      Under 30       step_2 2024-11-21 09:20:00   \n",
      "9          2  50 and above       step_3 2024-11-21 09:45:00   \n",
      "\n",
      "       next_step_time visit_time_diff  \n",
      "1 2024-11-20 08:15:00 0 days 00:15:00  \n",
      "2 2024-11-20 09:00:00 0 days 00:45:00  \n",
      "3 2024-11-20 09:30:00 0 days 00:30:00  \n",
      "4 2024-11-20 10:00:00 0 days 00:30:00  \n",
      "6 2024-11-21 08:40:00 0 days 00:30:00  \n",
      "7 2024-11-21 09:20:00 0 days 00:40:00  \n",
      "8 2024-11-21 09:45:00 0 days 00:25:00  \n",
      "9 2024-11-21 10:00:00 0 days 00:15:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\AppData\\Local\\Temp\\ipykernel_6272\\390851564.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_df['visit_time_diff'] = group_df['next_step_time'] - group_df['date_time']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data (same as before)\n",
    "data = {\n",
    "    'process_step': ['confirm', 'start', 'step_1', 'step_2', 'step_3', 'confirm', 'start', 'step_1', 'step_2', 'step_3'],\n",
    "    'date_time': pd.to_datetime([\n",
    "        '2024-11-20 10:00:00', '2024-11-20 08:00:00', '2024-11-20 08:15:00', \n",
    "        '2024-11-20 09:00:00', '2024-11-20 09:30:00', '2024-11-21 10:00:00', \n",
    "        '2024-11-21 08:10:00', '2024-11-21 08:40:00', '2024-11-21 09:20:00', '2024-11-21 09:45:00'\n",
    "    ]),\n",
    "    'client_id': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n",
    "    'variation': ['Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test', 'Test'],\n",
    "    'process_duration': [120, 150, 200, 250, 130, 180, 160, 270, 110, 240],  # process duration in seconds\n",
    "    'clnt_age': [25, 35, 42, 55, 29, 48, 33, 60, 19, 52]  # Client age\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_merged = pd.DataFrame(data)\n",
    "\n",
    "# Define age bins and labels\n",
    "bins = [0, 30, 40, 50, 100]  # Age bins\n",
    "labels = ['Under 30', '30-39', '40-49', '50 and above']  # Age group labels\n",
    "\n",
    "# Categorize ages into the defined bins and add a new 'age_group' column\n",
    "df_merged['age_group'] = pd.cut(df_merged['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "# Ensure date_time is in datetime format\n",
    "df_merged['date_time'] = pd.to_datetime(df_merged['date_time'], errors='coerce')\n",
    "\n",
    "# Filter for the test group only\n",
    "test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "# Sort by client_id and date_time to ensure chronological order of visits\n",
    "test_group = test_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "# Function to calculate completion time for each step and client visit\n",
    "def calculate_completion_time_by_visit(group_df):\n",
    "    # Create a new column to store the next step time\n",
    "    group_df['next_step_time'] = group_df.groupby('client_id')['date_time'].shift(-1)\n",
    "    \n",
    "    # Drop rows where the next step does not exist (i.e., NaT)\n",
    "    group_df = group_df.dropna(subset=['next_step_time'])\n",
    "    \n",
    "    # Calculate the time between consecutive visits (this is the time difference between each visit)\n",
    "    group_df['visit_time_diff'] = group_df['next_step_time'] - group_df['date_time']\n",
    "    \n",
    "    # Only keep relevant columns\n",
    "    return group_df[['client_id', 'age_group', 'process_step', 'date_time', 'next_step_time', 'visit_time_diff']]\n",
    "\n",
    "# Apply the function to the test group\n",
    "test_group_visit_times = calculate_completion_time_by_visit(test_group)\n",
    "\n",
    "# Display the results\n",
    "print(test_group_visit_times)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "test_group_visit_times.to_csv('test_group_visit_times.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee725e93-2bad-4e4c-8278-ebe89c87712f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
