{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e0e0b40-a0f0-40de-9f1d-d51a41881c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 11:26:19.359 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 145\u001b[0m\n\u001b[0;32m    142\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# New Aggregation for Number of Accounts, Calls, and Logons\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m logs_calls_accounts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_group\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_accts\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalls_6_mnth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogons_6_mnth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    149\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Plot for Average Number of Accounts\u001b[39;00m\n\u001b[0;32m    152\u001b[0m plot_demographics(\n\u001b[0;32m    153\u001b[0m     data\u001b[38;5;241m=\u001b[39mlogs_calls_accounts,\n\u001b[0;32m    154\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_group\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_accounts.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load the CSV file and show information\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    url = r\"C:\\Users\\Cecilia\\Downloads\\ironhack\\coursework\\group_work\\group_project_week5_6\\second_project\\data\\clean\\combined_cleaned_data.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"File not found. Please check the file path.\")\n",
    "        return None\n",
    "\n",
    "# Function to handle different pages\n",
    "def handle_data_page(page: str, df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Handles the display of data-related pages based on user selection.\n",
    "    \n",
    "    Args:\n",
    "    page (str): The selected page from the sidebar.\n",
    "    df (pd.DataFrame): The DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        st.error(\"Data could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    if page == \"Data Summary\":\n",
    "        st.subheader(\"CSV Data Overview\")\n",
    "        st.write(f\"Number of rows: {df.shape[0]}\")\n",
    "        st.write(f\"Number of columns: {df.shape[1]}\")\n",
    "        st.write(\"First 5 rows of the dataset:\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "    elif page == \"Unique Values\":\n",
    "        show_unique_values_in_categorical_columns(df)\n",
    "\n",
    "    elif page == \"Basic Statistics\":\n",
    "        show_basic_statistics(df)\n",
    "\n",
    "    elif page == \"Demographics Analysis\":\n",
    "        show_demographics_analysis(df)\n",
    "\n",
    "    elif page == \"Hypothesis Testing\":\n",
    "        show_hypothesis_testing_page(df)\n",
    "\n",
    "    elif page == \"Process Duration Analysis\":\n",
    "        show_latest_starts(df)\n",
    "\n",
    "    elif page == \"Completion Time Analysis\":\n",
    "        calculate_and_display_completion_time(df)\n",
    "\n",
    "# Function to show the About the Project page\n",
    "def show_about_project():\n",
    "    st.title(\"About the Project\")\n",
    "    \n",
    "    st.header(\"Project Overview\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        An A/B test was set into motion from 3/15/2017 to 6/20/2017 by the Vanguard team.\n",
    "\n",
    "        Control Group: Clients interacted with Vanguard’s traditional online process.\n",
    "        Test Group: Clients experienced the new, spruced-up digital interface.\n",
    "\n",
    "        * Day 1 & 2 (Week 5)\n",
    "        EDA & Data Cleaning\n",
    "        Client behavior analysis - explained below (trying to find relations and come up with hypothesis)\n",
    "        * Day 3 (Week 5)\n",
    "        Performance Metrics\n",
    "        Success Indicators\n",
    "        Redesign Outcome\n",
    "        * Day 4 & 5 (Week 5)\n",
    "        Hypothesis Testing\n",
    "        Completion Rate\n",
    "        Completion Rate with a Cost-Effectiveness Threshold\n",
    "        Other Hypothesis Examples\n",
    "        Experiment Evaluation\n",
    "        Design Effectiveness\n",
    "        Duration Assessment\n",
    "        Additional Data Needs\n",
    "        * Day 1 & 2 (Week 6)\n",
    "        Tableau\n",
    "        Tableau Tasks\n",
    "        * Day 3 & 4 (Week 6)\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    st.header(\"Getting Started\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        ## Metadata\n",
    "        This comprehensive set of fields will guide your analysis, helping you unravel the intricacies of client behavior and preferences.\n",
    "\n",
    "        - **client_id**: Every client’s unique ID.\n",
    "        - **variation**: Indicates if a client was part of the experiment.\n",
    "        - **visitor_id**: A unique ID for each client-device combination.\n",
    "        - **visit_id**: A unique ID for each web visit/session.\n",
    "        - **process_step**: Marks each step in the digital process.\n",
    "        - **date_time**: Timestamp of each web activity.\n",
    "        - **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "        - **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "        - **clnt_age**: Indicates the age of the client.\n",
    "        - **gendr**: Specifies the client’s gender.\n",
    "        - **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "        - **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "        - **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "        - **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months.\n",
    "\n",
    "        ## Bonus: Additional Tasks (Optional)\n",
    "        If you complete all of the tasks and have some extra time before the presentation, you can explore the following additional questions and tasks:\n",
    "\n",
    "        Client Behavior Analysis\n",
    "        Power and Effect Size\n",
    "        Streamlit\n",
    "        Add Streamlit to your project to achieve Customization and Real-time Analysis\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "# Function to show unique values in categorical columns\n",
    "def show_unique_values_in_categorical_columns(df):\n",
    "    st.title(\"Unique Values in Categorical Columns\")\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    if not categorical_columns:\n",
    "        st.warning(\"No categorical columns found in the file.\")\n",
    "        return\n",
    "\n",
    "    st.subheader(\"Unique Values in Categorical Columns:\")\n",
    "    for column in categorical_columns:\n",
    "        unique_values = df[column].unique()\n",
    "        st.write(f\"Column: {column}\")\n",
    "        st.write(f\"Unique values: {unique_values}\")\n",
    "\n",
    "# Function to show basic statistics for numeric columns\n",
    "def show_basic_statistics(df):\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    if numeric_df.empty:\n",
    "        st.warning(\"No numeric columns found in the file.\")\n",
    "        return\n",
    "    \n",
    "    st.subheader(\"Basic Statistics for Numeric Columns:\")\n",
    "    statistics = numeric_df.describe().T  # Transpose for better readability\n",
    "    st.write(statistics)\n",
    "\n",
    "# Function to calculate and display logs_calls_accounts if necessary\n",
    "def calculate_logs_calls_accounts(df):\n",
    "    # Perform the aggregation only when necessary\n",
    "    return df.groupby(['gender', 'age_group']).agg({\n",
    "        'num_accts': 'mean',\n",
    "        'calls_6_mnth': 'mean',\n",
    "        'logons_6_mnth': 'mean'\n",
    "    }).reset_index().round(2)\n",
    "\n",
    "def plot_demographics(data, x, y, hue, title, ylabel, filename, linestyle='-', marker='o'):\n",
    "    \"\"\"\n",
    "    Helper function to create and save a line plot for demographic data.\n",
    "    \n",
    "    Args:\n",
    "    data (DataFrame): The data to plot.\n",
    "    x (str): The column name for the x-axis.\n",
    "    y (str): The column name for the y-axis.\n",
    "    hue (str): The column name for the hue (color differentiation).\n",
    "    title (str): The title of the plot.\n",
    "    ylabel (str): The label for the y-axis.\n",
    "    filename (str): The filename to save the plot.\n",
    "    linestyle (str): The line style for the plot (default is solid).\n",
    "    marker (str): The marker style for the plot (default is 'o').\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(\n",
    "        data=data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        marker=marker,\n",
    "        linestyle=linestyle,\n",
    "        palette='coolwarm'\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(\"Age Group\")\n",
    "    plt.legend(title=\"Gender\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "# New Aggregation for Number of Accounts, Calls, and Logons\n",
    "logs_calls_accounts = df.groupby(['gender', 'age_group']).agg({\n",
    "    'num_accts': 'mean',\n",
    "    'calls_6_mnth': 'mean',\n",
    "    'logons_6_mnth': 'mean'\n",
    "}).reset_index().round(2)\n",
    "\n",
    "# Plot for Average Number of Accounts\n",
    "plot_demographics(\n",
    "    data=logs_calls_accounts,\n",
    "    x='age_group',\n",
    "    y='num_accts',\n",
    "    hue='gender',\n",
    "    title=\"Average Number of Accounts\",\n",
    "    ylabel=\"Average Number of Accounts\",\n",
    "    filename=\"average_accounts.png\"\n",
    ")\n",
    "\n",
    "# Plot for Calls in the Last 6 Months\n",
    "plot_demographics(\n",
    "    data=logs_calls_accounts,\n",
    "    x='age_group',\n",
    "    y='calls_6_mnth',\n",
    "    hue='gender',\n",
    "    title=\"Average Calls in Last 6 Months\",\n",
    "    ylabel=\"Average Calls\",\n",
    "    filename=\"average_calls.png\",\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "# Plot for Logons in the Last 6 Months\n",
    "plot_demographics(\n",
    "    data=logs_calls_accounts,\n",
    "    x='age_group',\n",
    "    y='logons_6_mnth',\n",
    "    hue='gender',\n",
    "    title=\"Average Logons in Last 6 Months\",\n",
    "    ylabel=\"Average Logons\",\n",
    "    filename=\"average_logs.png\",\n",
    "    linestyle=':'\n",
    ")\n",
    "\n",
    "st.write(\"Demographics analysis will be displayed here.\")\n",
    "\n",
    "# Function for two-proportion z-test\n",
    "def two_proportion_z_test(p1, p2, n1, n2):\n",
    "    P = (p1 * n1 + p2 * n2) / (n1 + n2)\n",
    "    SE = (P * (1 - P) * (1 / n1 + 1 / n2)) ** 0.5\n",
    "    z = (p1 - p2) / SE\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))  # Two-tailed test\n",
    "    return z, p_value\n",
    "\n",
    "# Function to show hypothesis testing page\n",
    "def show_hypothesis_testing_page(df):\n",
    "    st.title(\"Hypothesis Testing for Completion Rates\")\n",
    "    \n",
    "    available_columns = df.columns\n",
    "    st.write(f\"Available columns in the dataset: {available_columns}\")\n",
    "\n",
    "    if 'completion_rate' not in available_columns:\n",
    "        if 'completed_visits' in available_columns and 'started_visits' in available_columns:\n",
    "            df['completion_rate'] = df['completed_visits'] / df['started_visits'] * 100\n",
    "        else:\n",
    "            st.error(\"Missing required columns ('completed_visits' or 'started_visits') to calculate 'completion_rate'.\")\n",
    "            return\n",
    "\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    steps = ['confirm', 'step_1', 'step_2', 'step_3']\n",
    "\n",
    "    for step in steps:\n",
    "        st.subheader(f\"Step: {step}\")\n",
    "        \n",
    "        control_completions = control_group[control_group['process_step'] == step]['completion_rate'].values[0]\n",
    "        test_completions = test_group[test_group['process_step'] == step]['completion_rate'].values[0]\n",
    "        \n",
    "        control_total = control_group[control_group['process_step'] == step]['started_visits'].values[0]\n",
    "        test_total = test_group[test_group['process_step'] == step]['started_visits'].values[0]\n",
    "\n",
    "        p_control = control_completions / 100\n",
    "        p_test = test_completions / 100\n",
    "        \n",
    "        z_stat, p_value = two_proportion_z_test(p_control, p_test, control_total, test_total)\n",
    "        \n",
    "        st.write(f\"Z-statistic: {z_stat:.4f}\")\n",
    "        st.write(f\"P-value: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            st.write(f\"**Reject the null hypothesis**: There is a significant difference in completion rates between control and test group for step: {step}.\")\n",
    "        else:\n",
    "            st.write(f\"**Fail to reject the null hypothesis**: There is no significant difference in completion rates between control and test group for step: {step}.\")\n",
    "        st.write(\"\\n\")\n",
    "\n",
    "    st.subheader(\"Hypothesis Test: Tenure\")\n",
    "    \n",
    "    control_unique = control_group.drop_duplicates(subset='client_id')\n",
    "    test_unique = test_group.drop_duplicates(subset='client_id')\n",
    "\n",
    "    control_tenure = control_unique['clnt_tenure_yr']\n",
    "    test_tenure = test_unique['clnt_tenure_yr']\n",
    "        \n",
    "    t_stat, p_value_tenure = stats.ttest_ind(control_tenure, test_tenure, equal_var=True)\n",
    "\n",
    "    st.write(f\"Average Tenure in Control group: {control_tenure.mean():.2f} years\")\n",
    "    st.write(f\"Average Tenure in Test group: {test_tenure.mean():.2f} years\")\n",
    "    st.write(f\"T-statistic: {t_stat:.4f}\")\n",
    "    st.write(f\"P-value: {p_value_tenure:.4f}\")\n",
    "\n",
    "    if p_value_tenure < 0.05:\n",
    "        st.write(\"**Reject the null hypothesis**: There is a significant difference in tenure between control and test groups.\")\n",
    "    else:\n",
    "        st.write(\"**Fail to reject the null hypothesis**: There is no significant difference in tenure between control and test groups.\")\n",
    "\n",
    "def show_latest_starts(df):\n",
    "    # Filter out the 'start' process steps\n",
    "    starts_only = df[df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Filter out the 'confirm' process steps\n",
    "    confirmation_only = df[df['process_step'] == 'confirm']\n",
    "    latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Merge the latest start and confirm steps\n",
    "    latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "    # Ensure 'date_time' columns are in datetime format\n",
    "    latest_start_confirms['date_time_start'] = pd.to_datetime(latest_start_confirms['date_time_start'], errors='coerce')\n",
    "    latest_start_confirms['date_time_confirm'] = pd.to_datetime(latest_start_confirms['date_time_confirm'], errors='coerce')\n",
    "\n",
    "    # Drop rows where either 'date_time_start' or 'date_time_confirm' is NaT\n",
    "    latest_start_confirms = latest_start_confirms.dropna(subset=['date_time_start', 'date_time_confirm'])\n",
    "\n",
    "    # Calculate process duration\n",
    "    latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "    # If you want the duration in minutes\n",
    "    latest_start_confirms['process_duration_minutes'] = latest_start_confirms['process_duration'].dt.total_seconds() / 60\n",
    "\n",
    "    st.subheader(\"Process Duration Analysis:\")\n",
    "    avg_duration = latest_start_confirms['process_duration_minutes'].mean()\n",
    "    mode_duration = latest_start_confirms['process_duration_minutes'].mode()[0]\n",
    "    median_duration = latest_start_confirms['process_duration_minutes'].median()\n",
    "\n",
    "    st.write(f\"Average Duration: {avg_duration:.2f} minutes\")\n",
    "    st.write(f\"Mode Duration: {mode_duration:.2f} minutes\")\n",
    "    st.write(f\"Median Duration: {median_duration:.2f} minutes\")\n",
    "\n",
    "# Function to calculate and display completion time for each step\n",
    "def calculate_and_display_completion_time(df):\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    control_group = control_group.sort_values(by=['client_id', 'date_time'])\n",
    "\n",
    "    control_group['next_step_time'] = control_group.groupby('client_id')['date_time'].shift(-1)\n",
    "    control_group = control_group.dropna(subset=['next_step_time'])\n",
    "    control_group['completion_time'] = control_group['next_step_time'] - control_group['date_time']\n",
    "\n",
    "    control_group['completion_time_minutes'] = control_group['completion_time'].dt.total_seconds() / 60\n",
    "\n",
    "    st.write(\"Average Completion Time by Process Step (Control Group):\")\n",
    "    avg_completion_time = control_group.groupby('process_step')['completion_time_minutes'].mean().reset_index()\n",
    "    st.write(avg_completion_time)\n",
    "\n",
    "# Page navigation setup\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function to run the Streamlit app for A/B Test Demo.\n",
    "    \n",
    "    Sets up the page configuration, loads data, and manages navigation\n",
    "    through different pages of the app.\n",
    "    \"\"\"\n",
    "    st.set_page_config(page_title=\"A/B Test Demo for Group 7\")\n",
    "    \n",
    "    # Ensure df is loaded here before using it\n",
    "    df = load_data()\n",
    "\n",
    "    # If df is None, show an error and don't continue\n",
    "    if df is None:\n",
    "        st.error(\"Data could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\"Select a page:\", [\n",
    "        \"About the Project\", \n",
    "        \"Data Summary\", \n",
    "        \"Unique Values\", \n",
    "        \"Basic Statistics\", \n",
    "        \"Demographics Analysis\", \n",
    "        \"Hypothesis Testing\",\n",
    "        \"Process Duration Analysis\",\n",
    "        \"Completion Time Analysis\"\n",
    "    ])\n",
    "\n",
    "    # Handle page navigation\n",
    "    if page == \"About the Project\":\n",
    "        show_about_project()\n",
    "    else:\n",
    "        handle_data_page(page, df)\n",
    "\n",
    "    # Example of conditional logic if you need the logs_calls_accounts aggregation:\n",
    "    if page == \"Demographics Analysis\":\n",
    "        logs_calls_accounts = calculate_logs_calls_accounts(df)\n",
    "        # Now you can use logs_calls_accounts for demographics analysis\n",
    "        st.write(logs_calls_accounts)\n",
    "\n",
    "# Run the main function when the script is executed\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad25dc6-d47c-4ab5-bdca-75f47556f32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
